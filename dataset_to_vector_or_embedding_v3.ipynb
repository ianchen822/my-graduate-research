{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55efc17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import ast\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "def check_users_and_business_from_valid_and_test_is_in_training_set(train_data, valid_data, test_data):\n",
    "    \n",
    "    # Check if users and businesses in the validation set are all in the training set\n",
    "    valid_users_in_train = valid_data['user_id'].isin(train_data['user_id']).all()\n",
    "    valid_businesses_in_train = valid_data['business_id'].isin(train_data['business_id']).all()\n",
    "\n",
    "    # Check if users and businesses in the test set are all in the training set\n",
    "    test_users_in_train = test_data['user_id'].isin(train_data['user_id']).all()\n",
    "    test_businesses_in_train = test_data['business_id'].isin(train_data['business_id']).all()\n",
    "\n",
    "    # Print the results\n",
    "    print('Are all users in the validation set also in the training set?', valid_users_in_train)\n",
    "    print('Are all businesses in the validation set also in the training set?', valid_businesses_in_train)\n",
    "    print('Are all users in the test set also in the training set?', test_users_in_train)\n",
    "    print('Are all businesses in the test set also in the training set?', test_businesses_in_train)\n",
    "\n",
    "\n",
    "def get_bert_sentence_cls_embedding(text):\n",
    "    \n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    model = BertModel.from_pretrained('bert-base-uncased')\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    cls_sentence_embedding = outputs.last_hidden_state[:, 0, :]  # Extract [CLS] token embedding\n",
    "    return cls_sentence_embedding\n",
    "\n",
    "def get_vector_or_embedding_and_save_to_txt(folder_file_path, data, column_id_name, column_to_tranform,\n",
    "                                     method=\"bert-base-uncased\", embedding_level=\"sentence_cls_embedding\"):\n",
    "    \n",
    "    # make sure file is empty\n",
    "    with open(folder_file_path, 'w') as output_file:\n",
    "        pass\n",
    "    \n",
    "    with open(folder_file_path, 'a') as output_file:\n",
    "\n",
    "        if method==\"bert-base-uncased\" and embedding_level==\"sentence_cls_embedding\":\n",
    "            # Iterate through user_reviews and Append Results to Text File\n",
    "            for index, row in data.iterrows():\n",
    "\n",
    "                _id = row[column_id_name]\n",
    "                text = row[column_to_tranform]\n",
    "\n",
    "                feature_vector = get_bert_sentence_cls_embedding(text)\n",
    "\n",
    "                # Convert PyTorch Tensor to a list for easy storage\n",
    "                feature_vector_list = feature_vector.squeeze().tolist()\n",
    "\n",
    "                # Convert the list to a string for storage\n",
    "                feature_vector_str = str(feature_vector_list)\n",
    "\n",
    "                # Write user_id and feature_vector_str to the text file\n",
    "                output_file.write(f\"{_id}\\t{feature_vector_str}\\n\")\n",
    "\n",
    "            # Print a message indicating the successful saving of feature vectors\n",
    "            print(f'Feature vectors saved to {folder_file_path}')\n",
    "\n",
    "\n",
    "def read_vector_or_embedding_txt_return_df(folder_file_path, data_columns):\n",
    "\n",
    "    data = []\n",
    "\n",
    "    with open(folder_file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Split the line into _id and vector(embedding)\n",
    "            _id, feature_vector_str = line.strip().split('\\t')\n",
    "\n",
    "            # Convert the vector string back to a list using ast.literal_eval\n",
    "            feature_vector = ast.literal_eval(feature_vector_str)\n",
    "\n",
    "            # Append _id and feature_vector to the data list\n",
    "            data.append([_id, feature_vector])\n",
    "\n",
    "    # Create the DataFrame\n",
    "    df = pd.DataFrame(data, columns=data_columns)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def training_dataset_get_vector_or_embedding(\n",
    "    folder_path,\n",
    "    argumented_results_data,\n",
    "    method=\"bert-base-uncased\", \n",
    "    embedding_level=\"sentence_cls_embedding\",\n",
    "    text_name=\"argumented_text_result\"):\n",
    "    \n",
    "    cols = list(argumented_results_data.columns)\n",
    "    id_column = [col for col in cols if 'id' in col.lower()][0]\n",
    "    forwhat_column = [col for col in cols if text_name in col.lower()][0]\n",
    "    \n",
    "    if text_name==\"argumented_text_result\":\n",
    "\n",
    "        # Get BERT embedding\n",
    "        output_file_path = f'{forwhat_column}_{method}_{embedding_level}.txt'\n",
    "        folder_file_path = os.path.join(folder_path, output_file_path)\n",
    "        get_vector_or_embedding_and_save_to_txt(folder_file_path, argumented_results_data, \n",
    "                                                method=method, embedding_level=embedding_level, \n",
    "                                                column_id_name=id_column, column_to_tranform=forwhat_column)\n",
    "\n",
    "        feature_vectors_df = read_vector_or_embedding_txt_return_df(folder_file_path, \n",
    "                                                data_columns=[id_column, f\"{forwhat_column}_feature_vector\"])\n",
    "\n",
    "        # Merge data\n",
    "        argumented_results_data_with_feature_vectors_df = pd.merge(argumented_results_data, feature_vectors_df, on=id_column)\n",
    "        \n",
    "        return argumented_results_data_with_feature_vectors_df\n",
    "\n",
    "    else:\n",
    "        print(\"Text name has not handled yet or wrong text name !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9c84191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are all users in the validation set also in the training set? True\n",
      "Are all businesses in the validation set also in the training set? True\n",
      "Are all users in the test set also in the training set? True\n",
      "Are all businesses in the test set also in the training set? True\n"
     ]
    }
   ],
   "source": [
    "# check if all user and business in validation set and test set also in the training set\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "folder_path = \"../original\"\n",
    "\n",
    "train_data = pd.read_csv(os.path.join(folder_path, \"research_training_set.csv\"))\n",
    "valid_data = pd.read_csv(os.path.join(folder_path, \"research_validation_set.csv\"))\n",
    "test_data = pd.read_csv(os.path.join(folder_path, \"research_test_set.csv\"))\n",
    "\n",
    "check_users_and_business_from_valid_and_test_is_in_training_set(train_data, valid_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d08694b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature vectors saved to ./user_concatenated_reviews_text_argumented_text_result_bert-base-uncased_sentence_cls_embedding.txt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_concatenated_reviews_text</th>\n",
       "      <th>system_role_content</th>\n",
       "      <th>prompt</th>\n",
       "      <th>user_concatenated_reviews_text_argumented_text_result</th>\n",
       "      <th>user_concatenated_reviews_text_argumented_text_result_feature_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2cKJFFNJ9XVyWBt62mWvA</td>\n",
       "      <td>When it comes to pastries... especially Italia...</td>\n",
       "      <td>test</td>\n",
       "      <td>test:</td>\n",
       "      <td>argumented text test</td>\n",
       "      <td>[-0.3077409565448761, -0.05624747276306152, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3s52C4zL_DHRK0ULG6qtg</td>\n",
       "      <td>Stopped in for a quick coffee and ice cream be...</td>\n",
       "      <td>test</td>\n",
       "      <td>test:</td>\n",
       "      <td>argumented text test</td>\n",
       "      <td>[-0.3077409565448761, -0.05624747276306152, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-FxsSuwDbIII7yo5BjHpiA</td>\n",
       "      <td>\"Ping! Pow! Boom! Bing!\" - Tommy DeVito, Goodf...</td>\n",
       "      <td>test</td>\n",
       "      <td>test:</td>\n",
       "      <td>argumented text test</td>\n",
       "      <td>[-0.3077409565448761, -0.05624747276306152, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-G7Zkl1wIWBBmD0KRy_sCw</td>\n",
       "      <td>I totally get the cult of Federal Donuts; the ...</td>\n",
       "      <td>test</td>\n",
       "      <td>test:</td>\n",
       "      <td>argumented text test</td>\n",
       "      <td>[-0.3077409565448761, -0.05624747276306152, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-GowNe73gDZs9MfS3ugJDQ</td>\n",
       "      <td>Been a little while since last I dropped by Br...</td>\n",
       "      <td>test</td>\n",
       "      <td>test:</td>\n",
       "      <td>argumented text test</td>\n",
       "      <td>[-0.3077409565448761, -0.05624747276306152, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1803</th>\n",
       "      <td>zsXoPyTcU8ThZGbtAB-Vug</td>\n",
       "      <td>Martinez women's Christmas dinner ...great tim...</td>\n",
       "      <td>test</td>\n",
       "      <td>test:</td>\n",
       "      <td>argumented text test</td>\n",
       "      <td>[-0.3077409565448761, -0.05624747276306152, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1804</th>\n",
       "      <td>zu-e06_BM_TdkAZEKMrIww</td>\n",
       "      <td>You can always count on the Foodery to have an...</td>\n",
       "      <td>test</td>\n",
       "      <td>test:</td>\n",
       "      <td>argumented text test</td>\n",
       "      <td>[-0.3077409565448761, -0.05624747276306152, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1805</th>\n",
       "      <td>zv7tpu7xeaNyAeFG03d2CA</td>\n",
       "      <td>I am simply only leaving one star so I leave a...</td>\n",
       "      <td>test</td>\n",
       "      <td>test:</td>\n",
       "      <td>argumented text test</td>\n",
       "      <td>[-0.3077409565448761, -0.05624747276306152, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1806</th>\n",
       "      <td>zwXmvn1op5LuFF2Kveqaug</td>\n",
       "      <td>Wooooow. So good.\\n\\nWith a pretty simple inte...</td>\n",
       "      <td>test</td>\n",
       "      <td>test:</td>\n",
       "      <td>argumented text test</td>\n",
       "      <td>[-0.3077409565448761, -0.05624747276306152, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1807</th>\n",
       "      <td>zyvxtbh5eJ86bVgk52Yflg</td>\n",
       "      <td>Oh man. I hadn't had a chance to stop in comet...</td>\n",
       "      <td>test</td>\n",
       "      <td>test:</td>\n",
       "      <td>argumented text test</td>\n",
       "      <td>[-0.3077409565448761, -0.05624747276306152, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1808 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     user_id  \\\n",
       "0     -2cKJFFNJ9XVyWBt62mWvA   \n",
       "1     -3s52C4zL_DHRK0ULG6qtg   \n",
       "2     -FxsSuwDbIII7yo5BjHpiA   \n",
       "3     -G7Zkl1wIWBBmD0KRy_sCw   \n",
       "4     -GowNe73gDZs9MfS3ugJDQ   \n",
       "...                      ...   \n",
       "1803  zsXoPyTcU8ThZGbtAB-Vug   \n",
       "1804  zu-e06_BM_TdkAZEKMrIww   \n",
       "1805  zv7tpu7xeaNyAeFG03d2CA   \n",
       "1806  zwXmvn1op5LuFF2Kveqaug   \n",
       "1807  zyvxtbh5eJ86bVgk52Yflg   \n",
       "\n",
       "                         user_concatenated_reviews_text system_role_content  \\\n",
       "0     When it comes to pastries... especially Italia...                test   \n",
       "1     Stopped in for a quick coffee and ice cream be...                test   \n",
       "2     \"Ping! Pow! Boom! Bing!\" - Tommy DeVito, Goodf...                test   \n",
       "3     I totally get the cult of Federal Donuts; the ...                test   \n",
       "4     Been a little while since last I dropped by Br...                test   \n",
       "...                                                 ...                 ...   \n",
       "1803  Martinez women's Christmas dinner ...great tim...                test   \n",
       "1804  You can always count on the Foodery to have an...                test   \n",
       "1805  I am simply only leaving one star so I leave a...                test   \n",
       "1806  Wooooow. So good.\\n\\nWith a pretty simple inte...                test   \n",
       "1807  Oh man. I hadn't had a chance to stop in comet...                test   \n",
       "\n",
       "     prompt user_concatenated_reviews_text_argumented_text_result  \\\n",
       "0     test:                               argumented text test      \n",
       "1     test:                               argumented text test      \n",
       "2     test:                               argumented text test      \n",
       "3     test:                               argumented text test      \n",
       "4     test:                               argumented text test      \n",
       "...     ...                                                ...      \n",
       "1803  test:                               argumented text test      \n",
       "1804  test:                               argumented text test      \n",
       "1805  test:                               argumented text test      \n",
       "1806  test:                               argumented text test      \n",
       "1807  test:                               argumented text test      \n",
       "\n",
       "     user_concatenated_reviews_text_argumented_text_result_feature_vector  \n",
       "0     [-0.3077409565448761, -0.05624747276306152, -0...                    \n",
       "1     [-0.3077409565448761, -0.05624747276306152, -0...                    \n",
       "2     [-0.3077409565448761, -0.05624747276306152, -0...                    \n",
       "3     [-0.3077409565448761, -0.05624747276306152, -0...                    \n",
       "4     [-0.3077409565448761, -0.05624747276306152, -0...                    \n",
       "...                                                 ...                    \n",
       "1803  [-0.3077409565448761, -0.05624747276306152, -0...                    \n",
       "1804  [-0.3077409565448761, -0.05624747276306152, -0...                    \n",
       "1805  [-0.3077409565448761, -0.05624747276306152, -0...                    \n",
       "1806  [-0.3077409565448761, -0.05624747276306152, -0...                    \n",
       "1807  [-0.3077409565448761, -0.05624747276306152, -0...                    \n",
       "\n",
       "[1808 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# business_id, name, address, city, state, postal_code, latitude, longitude, stars, review_count, is_open, attributes, categories, hours\n",
    "\n",
    "# user_id, name, review_count, yelping_since(time), useful, funny, cool, elite, friends, fans(count), \n",
    "# compliment_more, compliment_profile, compliment_cute, compliment_list, compliment_note, compliment_plain, \n",
    "# compliment_cool, compliment_funny, compliment_writer, compliment_photos\n",
    "\n",
    "folder_path = './'\n",
    "user_reviews_argumented = pd.read_csv(\"user_id_user_concatenated_reviews_text_with_argumented_results.csv\")\n",
    "user_reviews_argumented_text_with_feature_vectors_df = training_dataset_get_vector_or_embedding(\n",
    "    folder_path=folder_path,\n",
    "    argumented_results_data=user_reviews_argumented,\n",
    "    method=\"bert-base-uncased\", \n",
    "    embedding_level=\"sentence_cls_embedding\", \n",
    "    text_name=\"argumented_text_result\")\n",
    "user_reviews_argumented_text_with_feature_vectors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cc2ddac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature vectors saved to 13percent_5reviews_num_threshold_GPT-3.5 Turbo_random_stars_research_data/business_concatenated_reviews_bert-base-uncased_sentence_cls_embedding.txt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>business_concatenated_reviews_text</th>\n",
       "      <th>business_feature_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0TffRSXXIlBYVbb5AwfTg</td>\n",
       "      <td>Among Indian food fans in the Philly area, the...</td>\n",
       "      <td>[-0.011190894991159439, -0.14645609259605408, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1PG6k_iezwJmRZLB7f6og</td>\n",
       "      <td>We stumbled upon this place after a bridal sho...</td>\n",
       "      <td>[-0.06079084426164627, -0.23591890931129456, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4mDMBfT6N0d-VIUTKVaLg</td>\n",
       "      <td>Simply put: this place is an adorable hole on ...</td>\n",
       "      <td>[-0.15170690417289734, -0.029171377420425415, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-81BXpO5Fuk-RqCabS7LMw</td>\n",
       "      <td>What a great brewery! If you are looking to tr...</td>\n",
       "      <td>[-0.2533146142959595, -0.404371052980423, 0.45...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-AanHawaDlzWHQjrqRRWig</td>\n",
       "      <td>Meg's team runs so smoothly and I enjoy the se...</td>\n",
       "      <td>[-0.371690571308136, -0.29266345500946045, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1568</th>\n",
       "      <td>zropQGh2fc7PMpzd32vneQ</td>\n",
       "      <td>I ordered the bulgogi tacos with some chips an...</td>\n",
       "      <td>[-0.14535580575466156, -0.2953207194805145, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569</th>\n",
       "      <td>zujdPV3HT-Y-CKE1GgkMHQ</td>\n",
       "      <td>It's a decent place to go for pastries. So far...</td>\n",
       "      <td>[0.000845844391733408, -0.2679324448108673, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1570</th>\n",
       "      <td>zun6IVJa7wYe3wAPqWnPGw</td>\n",
       "      <td>I like this place better than Black Market Eat...</td>\n",
       "      <td>[-0.07951334863901138, -0.3137638568878174, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1571</th>\n",
       "      <td>zvzmKaltuHKPeEcBkiUp1w</td>\n",
       "      <td>I really wanted to like @WedgeCheeseShop , sin...</td>\n",
       "      <td>[0.11999098211526871, -0.08705776184797287, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>zz3E7kmJI2r2JseE6LAnrw</td>\n",
       "      <td>If I need to hit an Asian grocery, butcher, fi...</td>\n",
       "      <td>[0.09322559833526611, 0.14727383852005005, 0.3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1573 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 business_id  \\\n",
       "0     -0TffRSXXIlBYVbb5AwfTg   \n",
       "1     -1PG6k_iezwJmRZLB7f6og   \n",
       "2     -4mDMBfT6N0d-VIUTKVaLg   \n",
       "3     -81BXpO5Fuk-RqCabS7LMw   \n",
       "4     -AanHawaDlzWHQjrqRRWig   \n",
       "...                      ...   \n",
       "1568  zropQGh2fc7PMpzd32vneQ   \n",
       "1569  zujdPV3HT-Y-CKE1GgkMHQ   \n",
       "1570  zun6IVJa7wYe3wAPqWnPGw   \n",
       "1571  zvzmKaltuHKPeEcBkiUp1w   \n",
       "1572  zz3E7kmJI2r2JseE6LAnrw   \n",
       "\n",
       "                     business_concatenated_reviews_text  \\\n",
       "0     Among Indian food fans in the Philly area, the...   \n",
       "1     We stumbled upon this place after a bridal sho...   \n",
       "2     Simply put: this place is an adorable hole on ...   \n",
       "3     What a great brewery! If you are looking to tr...   \n",
       "4     Meg's team runs so smoothly and I enjoy the se...   \n",
       "...                                                 ...   \n",
       "1568  I ordered the bulgogi tacos with some chips an...   \n",
       "1569  It's a decent place to go for pastries. So far...   \n",
       "1570  I like this place better than Black Market Eat...   \n",
       "1571  I really wanted to like @WedgeCheeseShop , sin...   \n",
       "1572  If I need to hit an Asian grocery, butcher, fi...   \n",
       "\n",
       "                                business_feature_vector  \n",
       "0     [-0.011190894991159439, -0.14645609259605408, ...  \n",
       "1     [-0.06079084426164627, -0.23591890931129456, 0...  \n",
       "2     [-0.15170690417289734, -0.029171377420425415, ...  \n",
       "3     [-0.2533146142959595, -0.404371052980423, 0.45...  \n",
       "4     [-0.371690571308136, -0.29266345500946045, -0....  \n",
       "...                                                 ...  \n",
       "1568  [-0.14535580575466156, -0.2953207194805145, 0....  \n",
       "1569  [0.000845844391733408, -0.2679324448108673, 0....  \n",
       "1570  [-0.07951334863901138, -0.3137638568878174, 0....  \n",
       "1571  [0.11999098211526871, -0.08705776184797287, -0...  \n",
       "1572  [0.09322559833526611, 0.14727383852005005, 0.3...  \n",
       "\n",
       "[1573 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# folder_path = './'\n",
    "# business_reviews_argumented = pd.read_csv(\"business_id_business_concatenated_reviews_text_with_argumented_results.csv\")\n",
    "# business_reviews_argumented_text_with_feature_vectors_df = training_dataset_get_vector_or_embedding(\n",
    "#     folder_path=folder_path,\n",
    "#     argumented_results_data=business_reviews_argumented,\n",
    "#     method=\"bert-base-uncased\", \n",
    "#     embedding_level=\"sentence_cls_embedding\",\n",
    "#     text_name=\"argumented_text_result\")\n",
    "# business_reviews_argumented_text_with_feature_vectors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16858e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature vectors saved to 13percent_5reviews_num_threshold_GPT-3.5 Turbo_random_stars_research_data/categories_bert-base-uncased_sentence_cls_embedding.txt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>categories_feature_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EFci0tbSrb7wko6tpVDnbA</td>\n",
       "      <td>[-0.07826090604066849, 0.0407031811773777, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EPMHuTHu46B123ivRIZ-Xg</td>\n",
       "      <td>[0.15846343338489532, -0.04316771775484085, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>J-ciDDEdIHMcChGIyKZnOg</td>\n",
       "      <td>[-0.05295887589454651, -0.06621156632900238, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>teFjQxUqT8c-yxQdoILDVQ</td>\n",
       "      <td>[-0.3904491662979126, 0.06892769038677216, 0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IzyQVIJG8JAnOiRQPb0-wg</td>\n",
       "      <td>[-0.05826997384428978, -0.24565061926841736, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11191</th>\n",
       "      <td>jCKjT0w6BnPxNSZO9Q2uuw</td>\n",
       "      <td>[-0.1557040810585022, -0.23840990662574768, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11192</th>\n",
       "      <td>JDv3h1xRFIW8fXckqgTdRg</td>\n",
       "      <td>[0.1256754845380783, -0.181650310754776, 0.068...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11193</th>\n",
       "      <td>QGYzYUMsQe6k7__LD91E5w</td>\n",
       "      <td>[-0.07354993373155594, 0.15001621842384338, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11194</th>\n",
       "      <td>dRKztV_Vtl7AvZg052SgRQ</td>\n",
       "      <td>[-0.3296162486076355, -0.041647765785455704, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11195</th>\n",
       "      <td>oIH5YWPy_g61YXM6R900Wg</td>\n",
       "      <td>[-0.29594239592552185, 0.08493829518556595, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11196 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  business_id  \\\n",
       "0      EFci0tbSrb7wko6tpVDnbA   \n",
       "1      EPMHuTHu46B123ivRIZ-Xg   \n",
       "2      J-ciDDEdIHMcChGIyKZnOg   \n",
       "3      teFjQxUqT8c-yxQdoILDVQ   \n",
       "4      IzyQVIJG8JAnOiRQPb0-wg   \n",
       "...                       ...   \n",
       "11191  jCKjT0w6BnPxNSZO9Q2uuw   \n",
       "11192  JDv3h1xRFIW8fXckqgTdRg   \n",
       "11193  QGYzYUMsQe6k7__LD91E5w   \n",
       "11194  dRKztV_Vtl7AvZg052SgRQ   \n",
       "11195  oIH5YWPy_g61YXM6R900Wg   \n",
       "\n",
       "                               categories_feature_vector  \n",
       "0      [-0.07826090604066849, 0.0407031811773777, 0.2...  \n",
       "1      [0.15846343338489532, -0.04316771775484085, -0...  \n",
       "2      [-0.05295887589454651, -0.06621156632900238, 0...  \n",
       "3      [-0.3904491662979126, 0.06892769038677216, 0.4...  \n",
       "4      [-0.05826997384428978, -0.24565061926841736, 0...  \n",
       "...                                                  ...  \n",
       "11191  [-0.1557040810585022, -0.23840990662574768, 0....  \n",
       "11192  [0.1256754845380783, -0.181650310754776, 0.068...  \n",
       "11193  [-0.07354993373155594, 0.15001621842384338, 0....  \n",
       "11194  [-0.3296162486076355, -0.041647765785455704, 0...  \n",
       "11195  [-0.29594239592552185, 0.08493829518556595, 0....  \n",
       "\n",
       "[11196 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# folder_path='./'\n",
    "# categories_argumented = pd.read_csv(\"business_id_categories_with_argumented_results.csv\")\n",
    "# categories_argumented_text_with_feature_vectors_df = training_dataset_get_vector_or_embedding(\n",
    "#     folder_path=folder_path\n",
    "#     argumented_results_data=categories_argumented,\n",
    "#     method=\"bert-base-uncased\", \n",
    "#     embedding_level=\"sentence_cls_embedding\",\n",
    "#     text_name=\"argumented_text_result\")\n",
    "# categories_argumented_text_with_feature_vectors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51280483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (11196, 15)\n",
      "Valid data shape: (1400, 15)\n",
      "Test data shape: (1400, 15)\n"
     ]
    }
   ],
   "source": [
    "# merge the dataframe above to training_data, validation_data and test_data\n",
    "\n",
    "# import os\n",
    "\n",
    "# folder_path = \"../original\"\n",
    "\n",
    "# train_data = pd.read_csv(os.path.join(folder_path, \"research_training_set.csv\"))\n",
    "# valid_data = pd.read_csv(os.path.join(folder_path, \"research_validation_set.csv\"))\n",
    "# test_data = pd.read_csv(os.path.join(folder_path, \"research_test_set.csv\"))\n",
    "\n",
    "# folder_path = \"./\"\n",
    "# train_data = pd.merge(train_data, user_reviews_argumented_text_with_feature_vectors_df, on='user_id')\n",
    "# train_data = pd.merge(train_data, business_reviews_argumented_text_with_feature_vectors_df, on='business_id')\n",
    "# train_data = pd.merge(train_data, categories_argumented_text_with_feature_vectors_df, on='business_id')\n",
    "# print(\"Train data shape:\", train_data.shape)\n",
    "# # save as csv\n",
    "# train_data.to_csv(os.path.join(folder_path, \"research_training_set_with_argumented_text_and_feature_vectors.csv\"), index=False)\n",
    "\n",
    "# valid_data = pd.merge(valid_data, user_reviews_argumented_text_with_feature_vectors_df, on='user_id')\n",
    "# valid_data = pd.merge(valid_data, business_reviews_argumented_text_with_feature_vectors_df, on='business_id')\n",
    "# valid_data = pd.merge(valid_data, categories_argumented_text_with_feature_vectors_df, on='business_id')\n",
    "# print(\"Valid data shape:\", valid_data.shape)\n",
    "# # save as csv\n",
    "# valid_data.to_csv(os.path.join(folder_path, \"research_validation_set_with_argumented_text_and_feature_vectors.csv\"), index=False)\n",
    "\n",
    "# test_data = pd.merge(test_data, user_reviews_argumented_text_with_feature_vectors_df, on='user_id')\n",
    "# test_data = pd.merge(test_data, business_reviews_argumented_text_with_feature_vectors_df, on='business_id')\n",
    "# test_data = pd.merge(test_data, categories_argumented_text_with_feature_vectors_df, on='business_id')\n",
    "# print(\"Test data shape:\", test_data.shape)\n",
    "# # save as csv\n",
    "# test_data.to_csv(os.path.join(folder_path, \"research_test_set_with_argumented_text_and_feature_vectors.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
