{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55efc17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import ast\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# yelp datasets file\n",
    "yelp_datasets_path = '../../Data_preprocessing/yelp_datasets/'\n",
    "\n",
    "# yelp dataset (from yelp offical website)\n",
    "yelp_offical_dataset_path = yelp_datasets_path + 'yelp_dataset_official/'\n",
    "\n",
    "# business, user and review dataset\n",
    "yelp_academic_dataset_business_path = yelp_offical_dataset_path + 'yelp_academic_dataset_business.json'\n",
    "yelp_academic_dataset_user_path = yelp_offical_dataset_path + 'yelp_academic_dataset_user.json'\n",
    "yelp_academic_dataset_review_path = yelp_offical_dataset_path + 'yelp_academic_dataset_review.json'\n",
    "\n",
    "# yelp photo dataset (from yelp official website)\n",
    "yelp_offical_photo_dataset_path = yelp_datasets_path + 'yelp_dataset_official_photos/'\n",
    "\n",
    "# photo dataset\n",
    "photo_dataset_path = yelp_offical_photo_dataset_path + 'photos/'\n",
    "\n",
    "def check_users_and_business_from_valid_and_test_is_in_training_set(train_data, valid_data, test_data):\n",
    "    \n",
    "    # Check if users and businesses in the validation set are all in the training set\n",
    "    valid_users_in_train = valid_data['user_id'].isin(train_data['user_id']).all()\n",
    "    valid_businesses_in_train = valid_data['business_id'].isin(train_data['business_id']).all()\n",
    "\n",
    "    # Check if users and businesses in the test set are all in the training set\n",
    "    test_users_in_train = test_data['user_id'].isin(train_data['user_id']).all()\n",
    "    test_businesses_in_train = test_data['business_id'].isin(train_data['business_id']).all()\n",
    "\n",
    "    # Print the results\n",
    "    print('Are all users in the validation set also in the training set?', valid_users_in_train)\n",
    "    print('Are all businesses in the validation set also in the training set?', valid_businesses_in_train)\n",
    "    print('Are all users in the test set also in the training set?', test_users_in_train)\n",
    "    print('Are all businesses in the test set also in the training set?', test_businesses_in_train)\n",
    "\n",
    "\n",
    "def get_bert_sentence_cls_embedding(text):\n",
    "    \n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    model = BertModel.from_pretrained('bert-base-uncased')\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    cls_sentence_embedding = outputs.last_hidden_state[:, 0, :]  # Extract [CLS] token embedding\n",
    "    return cls_sentence_embedding\n",
    "\n",
    "def get_vector_or_embedding_and_save_to_txt(folder_file_path, data, column_id_name, column_to_tranform,\n",
    "                                     method=\"bert-base-uncased\", embedding_level=\"sentence_cls_embedding\"):\n",
    "    \n",
    "    # make sure file is empty\n",
    "    with open(folder_file_path, 'w') as output_file:\n",
    "        pass\n",
    "    \n",
    "    with open(folder_file_path, 'a') as output_file:\n",
    "\n",
    "        if method==\"bert-base-uncased\" and embedding_level==\"sentence_cls_embedding\":\n",
    "            # Iterate through user_reviews and Append Results to Text File\n",
    "            for index, row in data.iterrows():\n",
    "\n",
    "                _id = row[column_id_name]\n",
    "                text = row[column_to_tranform]\n",
    "\n",
    "                feature_vector = get_bert_sentence_cls_embedding(text)\n",
    "\n",
    "                # Convert PyTorch Tensor to a list for easy storage\n",
    "                feature_vector_list = feature_vector.squeeze().tolist()\n",
    "\n",
    "                # Convert the list to a string for storage\n",
    "                feature_vector_str = str(feature_vector_list)\n",
    "\n",
    "                # Write user_id and feature_vector_str to the text file\n",
    "                output_file.write(f\"{_id}\\t{feature_vector_str}\\n\")\n",
    "\n",
    "            # Print a message indicating the successful saving of feature vectors\n",
    "            print(f'Feature vectors saved to {folder_file_path}')\n",
    "\n",
    "\n",
    "def read_vector_or_embedding_txt_return_df(folder_file_path, data_columns):\n",
    "\n",
    "    data = []\n",
    "\n",
    "    with open(folder_file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Split the line into _id and vector(embedding)\n",
    "            _id, feature_vector_str = line.strip().split('\\t')\n",
    "\n",
    "            # Convert the vector string back to a list using ast.literal_eval\n",
    "            feature_vector = ast.literal_eval(feature_vector_str)\n",
    "\n",
    "            # Append _id and feature_vector to the data list\n",
    "            data.append([_id, feature_vector])\n",
    "\n",
    "    # Create the DataFrame\n",
    "    df = pd.DataFrame(data, columns=data_columns)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def training_dataset_get_vector_or_embedding(folder_name, train_data, business_data, user_data, \n",
    "                                   method=\"bert-base-uncased\", embedding_level=\"sentence_cls_embedding\",\n",
    "                                   text_name=\"user_concatenated_reviews\"):\n",
    "    \n",
    "    if text_name == \"user_concatenated_reviews\" or text_name == \"business_concatenated_reviews\":\n",
    "        \n",
    "        for_who = \"\"\n",
    "        \n",
    "        if text_name == \"user_concatenated_reviews\":\n",
    "            for_who = \"user\"\n",
    "        else:\n",
    "            for_who = \"business\"\n",
    "            \n",
    "        id_name = f\"{for_who}_id\"\n",
    "        column_to_tranform = f\"{text_name}_text\"\n",
    "        \n",
    "        # Preprocess Text Data\n",
    "        concatenated_reviews = train_data.groupby(id_name)['text'].apply(lambda x: ';'.join(x)).reset_index()\n",
    "        concatenated_reviews = concatenated_reviews.rename(columns={'text': column_to_tranform})\n",
    "        # Save as csv\n",
    "        concatenated_reviews.to_csv(os.path.join(folder_name, f'{text_name}.csv'), index=False)\n",
    "\n",
    "\n",
    "        # Get BERT embedding\n",
    "        output_file_path = f'{text_name}_{method}_{embedding_level}.txt'\n",
    "        folder_file_path = os.path.join(folder_name, output_file_path)\n",
    "        get_vector_or_embedding_and_save_to_txt(folder_file_path, concatenated_reviews, \n",
    "                                                method=method, embedding_level=embedding_level, \n",
    "                                                column_id_name=id_name, column_to_tranform=column_to_tranform)\n",
    "\n",
    "        feature_vectors_df = read_vector_or_embedding_txt_return_df(folder_file_path, \n",
    "                                                data_columns=[id_name, f\"{for_who}_feature_vector\"])\n",
    "\n",
    "        # Merge data\n",
    "        concatenated_reviews_with_feature_vectors_df = pd.merge(concatenated_reviews, feature_vectors_df, on=id_name)\n",
    "        \n",
    "        return concatenated_reviews_with_feature_vectors_df\n",
    "\n",
    "\n",
    "    elif text_name==\"categories\":\n",
    "\n",
    "        merged_data = pd.merge(train_data, business_data, on=\"business_id\", how=\"left\")\n",
    "\n",
    "        # Get BERT embedding\n",
    "        output_file_path = f'{text_name}_{method}_{embedding_level}.txt'\n",
    "        folder_file_path = os.path.join(folder_name, output_file_path)\n",
    "        \n",
    "        get_vector_or_embedding_and_save_to_txt(folder_file_path, merged_data, \n",
    "                                                method=method, embedding_level=embedding_level, \n",
    "                                                column_id_name=\"business_id\", column_to_tranform=text_name)\n",
    "\n",
    "        feature_vectors_df = read_vector_or_embedding_txt_return_df(folder_file_path, \n",
    "                                                data_columns=[\"business_id\", f\"{text_name}_feature_vector\"])\n",
    "        \n",
    "        feature_vectors_df = feature_vectors_df.drop_duplicates(subset=['business_id']).reset_index(drop=True)\n",
    "        \n",
    "        return feature_vectors_df\n",
    "\n",
    "    else:\n",
    "        print(\"Text name has not handled yet or wrong text name !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9c84191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are all users in the validation set also in the training set? True\n",
      "Are all businesses in the validation set also in the training set? True\n",
      "Are all users in the test set also in the training set? True\n",
      "Are all businesses in the test set also in the training set? True\n"
     ]
    }
   ],
   "source": [
    "# check if all user and business in validation set and test set also in the training set\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "business_data = pd.read_json(yelp_academic_dataset_business_path, lines=True, encoding='utf-8-sig')\n",
    "# user_data = pd.read_json(yelp_academic_dataset_user_path, lines=True, encoding='utf-8-sig')\n",
    "user_data = [] # prevent memory explode\n",
    "\n",
    "# folder_name = \"13percent_5reviews_num_threshold_GPT-3.5 Turbo_random_stars_research_data\"\n",
    "# folder_name = \"../13percent_5reviews_num_threshold_GPT-3.5 Turbo_random_stars_research_data\"\n",
    "folder_name = \"./\"\n",
    "\n",
    "train_data = pd.read_csv(os.path.join(folder_name, \"research_training_set.csv\"))\n",
    "valid_data = pd.read_csv(os.path.join(folder_name, \"research_validation_set.csv\"))\n",
    "test_data = pd.read_csv(os.path.join(folder_name, \"research_test_set.csv\"))\n",
    "\n",
    "check_users_and_business_from_valid_and_test_is_in_training_set(train_data, valid_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d08694b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature vectors saved to 13percent_5reviews_num_threshold_GPT-3.5 Turbo_random_stars_research_data/user_concatenated_reviews_bert-base-uncased_sentence_cls_embedding.txt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_concatenated_reviews_text</th>\n",
       "      <th>user_feature_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2cKJFFNJ9XVyWBt62mWvA</td>\n",
       "      <td>When it comes to pastries... especially Italia...</td>\n",
       "      <td>[-0.11832541972398758, -0.06039704009890556, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3s52C4zL_DHRK0ULG6qtg</td>\n",
       "      <td>Stopped in for a quick coffee and ice cream be...</td>\n",
       "      <td>[0.04805588349699974, -0.13977167010307312, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-FxsSuwDbIII7yo5BjHpiA</td>\n",
       "      <td>\"Ping! Pow! Boom! Bing!\" - Tommy DeVito, Goodf...</td>\n",
       "      <td>[-0.05209613963961601, 0.06487774848937988, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-G7Zkl1wIWBBmD0KRy_sCw</td>\n",
       "      <td>I totally get the cult of Federal Donuts; the ...</td>\n",
       "      <td>[0.01472178753465414, -0.23244208097457886, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-GowNe73gDZs9MfS3ugJDQ</td>\n",
       "      <td>Been a little while since last I dropped by Br...</td>\n",
       "      <td>[0.005706729367375374, -0.09477227181196213, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1803</th>\n",
       "      <td>zsXoPyTcU8ThZGbtAB-Vug</td>\n",
       "      <td>Martinez women's Christmas dinner ...great tim...</td>\n",
       "      <td>[-0.2649359703063965, -0.2814408242702484, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1804</th>\n",
       "      <td>zu-e06_BM_TdkAZEKMrIww</td>\n",
       "      <td>You can always count on the Foodery to have an...</td>\n",
       "      <td>[-0.3454887270927429, -0.1860538125038147, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1805</th>\n",
       "      <td>zv7tpu7xeaNyAeFG03d2CA</td>\n",
       "      <td>I am simply only leaving one star so I leave a...</td>\n",
       "      <td>[-0.19689643383026123, -0.11205922812223434, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1806</th>\n",
       "      <td>zwXmvn1op5LuFF2Kveqaug</td>\n",
       "      <td>Wooooow. So good.\\n\\nWith a pretty simple inte...</td>\n",
       "      <td>[-0.22505134344100952, -0.430458128452301, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1807</th>\n",
       "      <td>zyvxtbh5eJ86bVgk52Yflg</td>\n",
       "      <td>Oh man. I hadn't had a chance to stop in comet...</td>\n",
       "      <td>[-0.06650251895189285, -0.014085384085774422, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1808 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     user_id  \\\n",
       "0     -2cKJFFNJ9XVyWBt62mWvA   \n",
       "1     -3s52C4zL_DHRK0ULG6qtg   \n",
       "2     -FxsSuwDbIII7yo5BjHpiA   \n",
       "3     -G7Zkl1wIWBBmD0KRy_sCw   \n",
       "4     -GowNe73gDZs9MfS3ugJDQ   \n",
       "...                      ...   \n",
       "1803  zsXoPyTcU8ThZGbtAB-Vug   \n",
       "1804  zu-e06_BM_TdkAZEKMrIww   \n",
       "1805  zv7tpu7xeaNyAeFG03d2CA   \n",
       "1806  zwXmvn1op5LuFF2Kveqaug   \n",
       "1807  zyvxtbh5eJ86bVgk52Yflg   \n",
       "\n",
       "                         user_concatenated_reviews_text  \\\n",
       "0     When it comes to pastries... especially Italia...   \n",
       "1     Stopped in for a quick coffee and ice cream be...   \n",
       "2     \"Ping! Pow! Boom! Bing!\" - Tommy DeVito, Goodf...   \n",
       "3     I totally get the cult of Federal Donuts; the ...   \n",
       "4     Been a little while since last I dropped by Br...   \n",
       "...                                                 ...   \n",
       "1803  Martinez women's Christmas dinner ...great tim...   \n",
       "1804  You can always count on the Foodery to have an...   \n",
       "1805  I am simply only leaving one star so I leave a...   \n",
       "1806  Wooooow. So good.\\n\\nWith a pretty simple inte...   \n",
       "1807  Oh man. I hadn't had a chance to stop in comet...   \n",
       "\n",
       "                                    user_feature_vector  \n",
       "0     [-0.11832541972398758, -0.06039704009890556, 0...  \n",
       "1     [0.04805588349699974, -0.13977167010307312, 0....  \n",
       "2     [-0.05209613963961601, 0.06487774848937988, 0....  \n",
       "3     [0.01472178753465414, -0.23244208097457886, 0....  \n",
       "4     [0.005706729367375374, -0.09477227181196213, 0...  \n",
       "...                                                 ...  \n",
       "1803  [-0.2649359703063965, -0.2814408242702484, 0.1...  \n",
       "1804  [-0.3454887270927429, -0.1860538125038147, 0.2...  \n",
       "1805  [-0.19689643383026123, -0.11205922812223434, 0...  \n",
       "1806  [-0.22505134344100952, -0.430458128452301, -0....  \n",
       "1807  [-0.06650251895189285, -0.014085384085774422, ...  \n",
       "\n",
       "[1808 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# business_id, name, address, city, state, postal_code, latitude, longitude, stars, review_count, is_open, attributes, categories, hours\n",
    "\n",
    "# user_id, name, review_count, yelping_since(time), useful, funny, cool, elite, friends, fans(count), \n",
    "# compliment_more, compliment_profile, compliment_cute, compliment_list, compliment_note, compliment_plain, \n",
    "# compliment_cool, compliment_funny, compliment_writer, compliment_photos\n",
    "\n",
    "user_concatenated_reviews_with_feature_vectors_df = training_dataset_get_vector_or_embedding(folder_name, train_data, business_data, user_data, \n",
    "                                   method=\"bert-base-uncased\", embedding_level=\"sentence_cls_embedding\",\n",
    "                                   text_name=\"user_concatenated_reviews\")\n",
    "user_concatenated_reviews_with_feature_vectors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cc2ddac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature vectors saved to 13percent_5reviews_num_threshold_GPT-3.5 Turbo_random_stars_research_data/business_concatenated_reviews_bert-base-uncased_sentence_cls_embedding.txt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>business_concatenated_reviews_text</th>\n",
       "      <th>business_feature_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0TffRSXXIlBYVbb5AwfTg</td>\n",
       "      <td>Among Indian food fans in the Philly area, the...</td>\n",
       "      <td>[-0.011190894991159439, -0.14645609259605408, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1PG6k_iezwJmRZLB7f6og</td>\n",
       "      <td>We stumbled upon this place after a bridal sho...</td>\n",
       "      <td>[-0.06079084426164627, -0.23591890931129456, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4mDMBfT6N0d-VIUTKVaLg</td>\n",
       "      <td>Simply put: this place is an adorable hole on ...</td>\n",
       "      <td>[-0.15170690417289734, -0.029171377420425415, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-81BXpO5Fuk-RqCabS7LMw</td>\n",
       "      <td>What a great brewery! If you are looking to tr...</td>\n",
       "      <td>[-0.2533146142959595, -0.404371052980423, 0.45...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-AanHawaDlzWHQjrqRRWig</td>\n",
       "      <td>Meg's team runs so smoothly and I enjoy the se...</td>\n",
       "      <td>[-0.371690571308136, -0.29266345500946045, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1568</th>\n",
       "      <td>zropQGh2fc7PMpzd32vneQ</td>\n",
       "      <td>I ordered the bulgogi tacos with some chips an...</td>\n",
       "      <td>[-0.14535580575466156, -0.2953207194805145, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569</th>\n",
       "      <td>zujdPV3HT-Y-CKE1GgkMHQ</td>\n",
       "      <td>It's a decent place to go for pastries. So far...</td>\n",
       "      <td>[0.000845844391733408, -0.2679324448108673, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1570</th>\n",
       "      <td>zun6IVJa7wYe3wAPqWnPGw</td>\n",
       "      <td>I like this place better than Black Market Eat...</td>\n",
       "      <td>[-0.07951334863901138, -0.3137638568878174, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1571</th>\n",
       "      <td>zvzmKaltuHKPeEcBkiUp1w</td>\n",
       "      <td>I really wanted to like @WedgeCheeseShop , sin...</td>\n",
       "      <td>[0.11999098211526871, -0.08705776184797287, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>zz3E7kmJI2r2JseE6LAnrw</td>\n",
       "      <td>If I need to hit an Asian grocery, butcher, fi...</td>\n",
       "      <td>[0.09322559833526611, 0.14727383852005005, 0.3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1573 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 business_id  \\\n",
       "0     -0TffRSXXIlBYVbb5AwfTg   \n",
       "1     -1PG6k_iezwJmRZLB7f6og   \n",
       "2     -4mDMBfT6N0d-VIUTKVaLg   \n",
       "3     -81BXpO5Fuk-RqCabS7LMw   \n",
       "4     -AanHawaDlzWHQjrqRRWig   \n",
       "...                      ...   \n",
       "1568  zropQGh2fc7PMpzd32vneQ   \n",
       "1569  zujdPV3HT-Y-CKE1GgkMHQ   \n",
       "1570  zun6IVJa7wYe3wAPqWnPGw   \n",
       "1571  zvzmKaltuHKPeEcBkiUp1w   \n",
       "1572  zz3E7kmJI2r2JseE6LAnrw   \n",
       "\n",
       "                     business_concatenated_reviews_text  \\\n",
       "0     Among Indian food fans in the Philly area, the...   \n",
       "1     We stumbled upon this place after a bridal sho...   \n",
       "2     Simply put: this place is an adorable hole on ...   \n",
       "3     What a great brewery! If you are looking to tr...   \n",
       "4     Meg's team runs so smoothly and I enjoy the se...   \n",
       "...                                                 ...   \n",
       "1568  I ordered the bulgogi tacos with some chips an...   \n",
       "1569  It's a decent place to go for pastries. So far...   \n",
       "1570  I like this place better than Black Market Eat...   \n",
       "1571  I really wanted to like @WedgeCheeseShop , sin...   \n",
       "1572  If I need to hit an Asian grocery, butcher, fi...   \n",
       "\n",
       "                                business_feature_vector  \n",
       "0     [-0.011190894991159439, -0.14645609259605408, ...  \n",
       "1     [-0.06079084426164627, -0.23591890931129456, 0...  \n",
       "2     [-0.15170690417289734, -0.029171377420425415, ...  \n",
       "3     [-0.2533146142959595, -0.404371052980423, 0.45...  \n",
       "4     [-0.371690571308136, -0.29266345500946045, -0....  \n",
       "...                                                 ...  \n",
       "1568  [-0.14535580575466156, -0.2953207194805145, 0....  \n",
       "1569  [0.000845844391733408, -0.2679324448108673, 0....  \n",
       "1570  [-0.07951334863901138, -0.3137638568878174, 0....  \n",
       "1571  [0.11999098211526871, -0.08705776184797287, -0...  \n",
       "1572  [0.09322559833526611, 0.14727383852005005, 0.3...  \n",
       "\n",
       "[1573 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_concatenated_reviews_with_feature_vectors_df = training_dataset_get_vector_or_embedding(folder_name, train_data, business_data, user_data, \n",
    "                                   method=\"bert-base-uncased\", embedding_level=\"sentence_cls_embedding\",\n",
    "                                   text_name=\"business_concatenated_reviews\")\n",
    "business_concatenated_reviews_with_feature_vectors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16858e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature vectors saved to 13percent_5reviews_num_threshold_GPT-3.5 Turbo_random_stars_research_data/categories_bert-base-uncased_sentence_cls_embedding.txt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>categories_feature_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EFci0tbSrb7wko6tpVDnbA</td>\n",
       "      <td>[-0.07826090604066849, 0.0407031811773777, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EPMHuTHu46B123ivRIZ-Xg</td>\n",
       "      <td>[0.15846343338489532, -0.04316771775484085, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>J-ciDDEdIHMcChGIyKZnOg</td>\n",
       "      <td>[-0.05295887589454651, -0.06621156632900238, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>teFjQxUqT8c-yxQdoILDVQ</td>\n",
       "      <td>[-0.3904491662979126, 0.06892769038677216, 0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IzyQVIJG8JAnOiRQPb0-wg</td>\n",
       "      <td>[-0.05826997384428978, -0.24565061926841736, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11191</th>\n",
       "      <td>jCKjT0w6BnPxNSZO9Q2uuw</td>\n",
       "      <td>[-0.1557040810585022, -0.23840990662574768, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11192</th>\n",
       "      <td>JDv3h1xRFIW8fXckqgTdRg</td>\n",
       "      <td>[0.1256754845380783, -0.181650310754776, 0.068...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11193</th>\n",
       "      <td>QGYzYUMsQe6k7__LD91E5w</td>\n",
       "      <td>[-0.07354993373155594, 0.15001621842384338, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11194</th>\n",
       "      <td>dRKztV_Vtl7AvZg052SgRQ</td>\n",
       "      <td>[-0.3296162486076355, -0.041647765785455704, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11195</th>\n",
       "      <td>oIH5YWPy_g61YXM6R900Wg</td>\n",
       "      <td>[-0.29594239592552185, 0.08493829518556595, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11196 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  business_id  \\\n",
       "0      EFci0tbSrb7wko6tpVDnbA   \n",
       "1      EPMHuTHu46B123ivRIZ-Xg   \n",
       "2      J-ciDDEdIHMcChGIyKZnOg   \n",
       "3      teFjQxUqT8c-yxQdoILDVQ   \n",
       "4      IzyQVIJG8JAnOiRQPb0-wg   \n",
       "...                       ...   \n",
       "11191  jCKjT0w6BnPxNSZO9Q2uuw   \n",
       "11192  JDv3h1xRFIW8fXckqgTdRg   \n",
       "11193  QGYzYUMsQe6k7__LD91E5w   \n",
       "11194  dRKztV_Vtl7AvZg052SgRQ   \n",
       "11195  oIH5YWPy_g61YXM6R900Wg   \n",
       "\n",
       "                               categories_feature_vector  \n",
       "0      [-0.07826090604066849, 0.0407031811773777, 0.2...  \n",
       "1      [0.15846343338489532, -0.04316771775484085, -0...  \n",
       "2      [-0.05295887589454651, -0.06621156632900238, 0...  \n",
       "3      [-0.3904491662979126, 0.06892769038677216, 0.4...  \n",
       "4      [-0.05826997384428978, -0.24565061926841736, 0...  \n",
       "...                                                  ...  \n",
       "11191  [-0.1557040810585022, -0.23840990662574768, 0....  \n",
       "11192  [0.1256754845380783, -0.181650310754776, 0.068...  \n",
       "11193  [-0.07354993373155594, 0.15001621842384338, 0....  \n",
       "11194  [-0.3296162486076355, -0.041647765785455704, 0...  \n",
       "11195  [-0.29594239592552185, 0.08493829518556595, 0....  \n",
       "\n",
       "[11196 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories_feature_vectors_df = training_dataset_get_vector_or_embedding(folder_name, train_data, business_data, user_data, \n",
    "                                   method=\"bert-base-uncased\", embedding_level=\"sentence_cls_embedding\",\n",
    "                                   text_name=\"categories\")\n",
    "categories_feature_vectors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01ed1ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>categories_feature_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EFci0tbSrb7wko6tpVDnbA</td>\n",
       "      <td>[-0.07826090604066849, 0.0407031811773777, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EPMHuTHu46B123ivRIZ-Xg</td>\n",
       "      <td>[0.15846343338489532, -0.04316771775484085, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>J-ciDDEdIHMcChGIyKZnOg</td>\n",
       "      <td>[-0.05295887589454651, -0.06621156632900238, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>teFjQxUqT8c-yxQdoILDVQ</td>\n",
       "      <td>[-0.3904491662979126, 0.06892769038677216, 0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IzyQVIJG8JAnOiRQPb0-wg</td>\n",
       "      <td>[-0.05826997384428978, -0.24565061926841736, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1568</th>\n",
       "      <td>8xuhKP08513N2W32JOMW4Q</td>\n",
       "      <td>[-0.15446922183036804, -0.2641109526157379, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569</th>\n",
       "      <td>WAPhi7JdwIvdTBgM9KsxHA</td>\n",
       "      <td>[-0.13093726336956024, 0.024154286831617355, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1570</th>\n",
       "      <td>H91qZiLaUQEHNkDP4DO5pg</td>\n",
       "      <td>[0.05852658301591873, -0.2432709038257599, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1571</th>\n",
       "      <td>XpTNCVbO5wL1DtDyKzKqfA</td>\n",
       "      <td>[0.0391341857612133, 0.0245373472571373, 0.024...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>YwrL69clJBmO9-HgA7dfUA</td>\n",
       "      <td>[0.00363310519605875, -0.07027648389339447, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1573 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 business_id  \\\n",
       "0     EFci0tbSrb7wko6tpVDnbA   \n",
       "1     EPMHuTHu46B123ivRIZ-Xg   \n",
       "2     J-ciDDEdIHMcChGIyKZnOg   \n",
       "3     teFjQxUqT8c-yxQdoILDVQ   \n",
       "4     IzyQVIJG8JAnOiRQPb0-wg   \n",
       "...                      ...   \n",
       "1568  8xuhKP08513N2W32JOMW4Q   \n",
       "1569  WAPhi7JdwIvdTBgM9KsxHA   \n",
       "1570  H91qZiLaUQEHNkDP4DO5pg   \n",
       "1571  XpTNCVbO5wL1DtDyKzKqfA   \n",
       "1572  YwrL69clJBmO9-HgA7dfUA   \n",
       "\n",
       "                              categories_feature_vector  \n",
       "0     [-0.07826090604066849, 0.0407031811773777, 0.2...  \n",
       "1     [0.15846343338489532, -0.04316771775484085, -0...  \n",
       "2     [-0.05295887589454651, -0.06621156632900238, 0...  \n",
       "3     [-0.3904491662979126, 0.06892769038677216, 0.4...  \n",
       "4     [-0.05826997384428978, -0.24565061926841736, 0...  \n",
       "...                                                 ...  \n",
       "1568  [-0.15446922183036804, -0.2641109526157379, 0....  \n",
       "1569  [-0.13093726336956024, 0.024154286831617355, 0...  \n",
       "1570  [0.05852658301591873, -0.2432709038257599, 0.1...  \n",
       "1571  [0.0391341857612133, 0.0245373472571373, 0.024...  \n",
       "1572  [0.00363310519605875, -0.07027648389339447, -0...  \n",
       "\n",
       "[1573 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# categories_feature_vectors_df = categories_feature_vectors_df.drop_duplicates(subset=['business_id']).reset_index(drop=True)\n",
    "# categories_feature_vectors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51280483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (11196, 15)\n",
      "Valid data shape: (1400, 15)\n",
      "Test data shape: (1400, 15)\n"
     ]
    }
   ],
   "source": [
    "# merge the dataframe above to training_data, validation_data and test_data\n",
    "\n",
    "import os\n",
    "# folder_name = \"13percent_5reviews_num_threshold_GPT-3.5 Turbo_random_stars_research_data\"\n",
    "# folder_name = \"../13percent_5reviews_num_threshold_GPT-3.5 Turbo_random_stars_research_data\"\n",
    "folder_name = \"./\"\n",
    "\n",
    "train_data = pd.read_csv(os.path.join(folder_name, \"research_training_set.csv\"))\n",
    "valid_data = pd.read_csv(os.path.join(folder_name, \"research_validation_set.csv\"))\n",
    "test_data = pd.read_csv(os.path.join(folder_name, \"research_test_set.csv\"))\n",
    "\n",
    "train_data = pd.merge(train_data, user_concatenated_reviews_with_feature_vectors_df, on='user_id')\n",
    "train_data = pd.merge(train_data, business_concatenated_reviews_with_feature_vectors_df, on='business_id')\n",
    "train_data = pd.merge(train_data, categories_feature_vectors_df, on='business_id')\n",
    "print(\"Train data shape:\", train_data.shape)\n",
    "# save as csv\n",
    "train_data.to_csv(os.path.join(folder_name, \"research_training_set_with_concatenated_reviews_and_feature_vectors.csv\"), index=False)\n",
    "\n",
    "valid_data = pd.merge(valid_data, user_concatenated_reviews_with_feature_vectors_df, on='user_id')\n",
    "valid_data = pd.merge(valid_data, business_concatenated_reviews_with_feature_vectors_df, on='business_id')\n",
    "valid_data = pd.merge(valid_data, categories_feature_vectors_df, on='business_id')\n",
    "print(\"Valid data shape:\", valid_data.shape)\n",
    "# save as csv\n",
    "valid_data.to_csv(os.path.join(folder_name, \"research_validation_set_with_concatenated_reviews_and_feature_vectors.csv\"), index=False)\n",
    "\n",
    "test_data = pd.merge(test_data, user_concatenated_reviews_with_feature_vectors_df, on='user_id')\n",
    "test_data = pd.merge(test_data, business_concatenated_reviews_with_feature_vectors_df, on='business_id')\n",
    "test_data = pd.merge(test_data, categories_feature_vectors_df, on='business_id')\n",
    "print(\"Test data shape:\", test_data.shape)\n",
    "# save as csv\n",
    "test_data.to_csv(os.path.join(folder_name, \"research_test_set_with_concatenated_reviews_and_feature_vectors.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
