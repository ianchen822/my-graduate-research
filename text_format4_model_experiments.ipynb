{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75a47bd8",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e0471d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e408964",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# data_path = '../Data_preprocessing/'\n",
    "training_data_path = 'research_training_set_with_concatenated_reviews_business_categories_and_feature_vectors.csv'\n",
    "training_data = pd.read_csv(training_data_path)\n",
    "# training_data.head()\n",
    "\n",
    "# data_path = '../Data_preprocessing/'\n",
    "validation_data_path = 'research_validation_set_with_concatenated_reviews_business_categories_and_feature_vectors.csv'\n",
    "validation_data = pd.read_csv(validation_data_path)\n",
    "# validation_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9238755d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Validation Data preprocessing\n",
    "\n",
    "columns_to_train = ['user_feature_vector', 'business_feature_vector']\n",
    "# columns_to_train = ['user_feature_vector', 'business_feature_vector', \"business_categories_feature_vector\"]\n",
    "\n",
    "concatenated_vectors = []\n",
    "for i in range(len(training_data)):\n",
    "    col_vectors = []\n",
    "    for col in columns_to_train:\n",
    "        col_vectors.append(np.array(eval(training_data[col][i])))\n",
    "    concatenated_vector = np.concatenate(col_vectors)\n",
    "    concatenated_vectors.append(concatenated_vector)\n",
    "\n",
    "X_train = np.array(concatenated_vectors)\n",
    "y_train = np.array(training_data['stars'])\n",
    "\n",
    "concatenated_vectors = []\n",
    "for i in range(len(validation_data)):\n",
    "    col_vectors = []\n",
    "    for col in columns_to_train:\n",
    "        col_vectors.append(np.array(eval(validation_data[col][i])))\n",
    "    concatenated_vector = np.concatenate(col_vectors)\n",
    "    concatenated_vectors.append(concatenated_vector)\n",
    "\n",
    "X_valid = np.array(concatenated_vectors)\n",
    "y_valid = np.array(validation_data['stars'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616a97a1",
   "metadata": {},
   "source": [
    "# Load written code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ce9e0443",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import nbformat\n",
    "\n",
    "def load_notebook(notebook_path):\n",
    "    with open(notebook_path, 'r', encoding='utf-8') as f:\n",
    "        nb = nbformat.read(f, as_version=4)\n",
    "    code_cells = [cell.source for cell in nb.cells if cell.cell_type == 'code']\n",
    "    exec('\\n'.join(code_cells), globals())\n",
    "\n",
    "# import written function and variable\n",
    "\n",
    "parent_directory = Path('../../../')\n",
    "# parent_directory = Path('../../')\n",
    "model_zoo_path = parent_directory / 'model_zoo.ipynb'\n",
    "model_training_validation_testing_function_path = parent_directory / 'model_train_val_test_function.ipynb'\n",
    "# model_training_validation_params_path = parent_directory / 'model_train_val_params.ipynb'\n",
    "\n",
    "load_notebook(model_zoo_path)\n",
    "load_notebook(model_training_validation_testing_function_path)\n",
    "# load_notebook(model_training_validation_params_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8876923",
   "metadata": {},
   "source": [
    "# FM experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cdc69793",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(X_train[0])\n",
    "embedding_size = 768\n",
    "field_num = len(columns_to_train)\n",
    "\n",
    "FM_params = {\n",
    "    'hyperparameters': {\n",
    "        'input_dim': input_dim, \n",
    "#         'factors_num': [5, 10, 15],\n",
    "#         'factors_num': [i+1 for i in range(20)]\n",
    "#         'factors_num': [5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "#         'factors_num': [2**i for i in range(3, 7)],\n",
    "        'factors_num': 8\n",
    "    },\n",
    "    \n",
    "    'task_type': 'Regression', 'loss_type': 'MSE', 'optimizer_type': 'Adam', \n",
    "#   'dl_learning_rate': [0.01, 0.02, 0.001], \n",
    "    'dl_learning_rate': 0.001,\n",
    "    'epochs_num': 100, \n",
    "#   'batch_size': [100, 500, 1000]\n",
    "    'batch_size': 512\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b6683893",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/04/08 16:53:55 INFO mlflow.tracking.fluent: Experiment with name 'origin_text_f4/FM' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training FM model ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(              Timestamp Model_name    Training_for  FM_input_dim  \\\n",
       " 0   2024-04-08 16:53:56         FM  for_validation          1536   \n",
       " 1   2024-04-08 16:53:56         FM  for_validation          1536   \n",
       " 2   2024-04-08 16:53:56         FM  for_validation          1536   \n",
       " 3   2024-04-08 16:53:56         FM  for_validation          1536   \n",
       " 4   2024-04-08 16:53:56         FM  for_validation          1536   \n",
       " ..                  ...        ...             ...           ...   \n",
       " 95  2024-04-08 16:54:09         FM  for_validation          1536   \n",
       " 96  2024-04-08 16:54:09         FM  for_validation          1536   \n",
       " 97  2024-04-08 16:54:09         FM  for_validation          1536   \n",
       " 98  2024-04-08 16:54:09         FM  for_validation          1536   \n",
       " 99  2024-04-08 16:54:10         FM  for_validation          1536   \n",
       " \n",
       "     FM_factors_num   Task_type Loss_type Optimizer_type  DL_learning_rate  \\\n",
       " 0                8  Regression      RMSE           Adam             0.001   \n",
       " 1                8  Regression      RMSE           Adam             0.001   \n",
       " 2                8  Regression      RMSE           Adam             0.001   \n",
       " 3                8  Regression      RMSE           Adam             0.001   \n",
       " 4                8  Regression      RMSE           Adam             0.001   \n",
       " ..             ...         ...       ...            ...               ...   \n",
       " 95               8  Regression      RMSE           Adam             0.001   \n",
       " 96               8  Regression      RMSE           Adam             0.001   \n",
       " 97               8  Regression      RMSE           Adam             0.001   \n",
       " 98               8  Regression      RMSE           Adam             0.001   \n",
       " 99               8  Regression      RMSE           Adam             0.001   \n",
       " \n",
       "     Epochs_num  ...  Epoch/Epochs_num  Avg_Loss  Avg_RMSE   Avg_MSE  \\\n",
       " 0          100  ...           1th/100  1.229385  1.229384  1.564195   \n",
       " 1          100  ...           2th/100  1.005392  1.005392  1.012306   \n",
       " 2          100  ...           3th/100  0.959953  0.959953  0.922879   \n",
       " 3          100  ...           4th/100  0.938537  0.938537  0.881966   \n",
       " 4          100  ...           5th/100  0.931386  0.931385  0.868414   \n",
       " ..         ...  ...               ...       ...       ...       ...   \n",
       " 95         100  ...          96th/100  0.682326  0.682326  0.466341   \n",
       " 96         100  ...          97th/100  0.669443  0.669442  0.448639   \n",
       " 97         100  ...          98th/100  0.676413  0.676412  0.458012   \n",
       " 98         100  ...          99th/100  0.677269  0.677268  0.459143   \n",
       " 99         100  ...         100th/100  0.664430  0.664429  0.442194   \n",
       " \n",
       "     Avg_Accuracy  Avg_AUC_score  Avg_F1  Avg_Precision  Avg_Recall  \\\n",
       " 0            0.0            0.0     0.0            0.0         0.0   \n",
       " 1            0.0            0.0     0.0            0.0         0.0   \n",
       " 2            0.0            0.0     0.0            0.0         0.0   \n",
       " 3            0.0            0.0     0.0            0.0         0.0   \n",
       " 4            0.0            0.0     0.0            0.0         0.0   \n",
       " ..           ...            ...     ...            ...         ...   \n",
       " 95           0.0            0.0     0.0            0.0         0.0   \n",
       " 96           0.0            0.0     0.0            0.0         0.0   \n",
       " 97           0.0            0.0     0.0            0.0         0.0   \n",
       " 98           0.0            0.0     0.0            0.0         0.0   \n",
       " 99           0.0            0.0     0.0            0.0         0.0   \n",
       " \n",
       "     Avg_Specificity  \n",
       " 0               0.0  \n",
       " 1               0.0  \n",
       " 2               0.0  \n",
       " 3               0.0  \n",
       " 4               0.0  \n",
       " ..              ...  \n",
       " 95              0.0  \n",
       " 96              0.0  \n",
       " 97              0.0  \n",
       " 98              0.0  \n",
       " 99              0.0  \n",
       " \n",
       " [100 rows x 21 columns],\n",
       "               Timestamp Model_name  FM_input_dim  FM_factors_num   Task_type  \\\n",
       " 0   2024-04-08 16:53:56         FM          1536               8  Regression   \n",
       " 1   2024-04-08 16:53:56         FM          1536               8  Regression   \n",
       " 2   2024-04-08 16:53:56         FM          1536               8  Regression   \n",
       " 3   2024-04-08 16:53:56         FM          1536               8  Regression   \n",
       " 4   2024-04-08 16:53:56         FM          1536               8  Regression   \n",
       " ..                  ...        ...           ...             ...         ...   \n",
       " 95  2024-04-08 16:54:09         FM          1536               8  Regression   \n",
       " 96  2024-04-08 16:54:09         FM          1536               8  Regression   \n",
       " 97  2024-04-08 16:54:09         FM          1536               8  Regression   \n",
       " 98  2024-04-08 16:54:09         FM          1536               8  Regression   \n",
       " 99  2024-04-08 16:54:10         FM          1536               8  Regression   \n",
       " \n",
       "    Loss_type Optimizer_type  DL_learning_rate  Epochs_num  Batch_size  \\\n",
       " 0       RMSE           Adam             0.001         100         512   \n",
       " 1       RMSE           Adam             0.001         100         512   \n",
       " 2       RMSE           Adam             0.001         100         512   \n",
       " 3       RMSE           Adam             0.001         100         512   \n",
       " 4       RMSE           Adam             0.001         100         512   \n",
       " ..       ...            ...               ...         ...         ...   \n",
       " 95      RMSE           Adam             0.001         100         512   \n",
       " 96      RMSE           Adam             0.001         100         512   \n",
       " 97      RMSE           Adam             0.001         100         512   \n",
       " 98      RMSE           Adam             0.001         100         512   \n",
       " 99      RMSE           Adam             0.001         100         512   \n",
       " \n",
       "    Epoch/Epochs_num            Loss      RMSE       MSE  Accuracy  AUC_score  \\\n",
       " 0           1th/100  tensor(1.1169)  1.116850  1.247354       0.0        0.0   \n",
       " 1           2th/100  tensor(1.0201)  1.020137  1.040680       0.0        0.0   \n",
       " 2           3th/100  tensor(1.0065)  1.006541  1.013125       0.0        0.0   \n",
       " 3           4th/100  tensor(1.0117)  1.011721  1.023579       0.0        0.0   \n",
       " 4           5th/100  tensor(0.9992)  0.999208  0.998417       0.0        0.0   \n",
       " ..              ...             ...       ...       ...       ...        ...   \n",
       " 95         96th/100  tensor(1.0538)  1.053823  1.110543       0.0        0.0   \n",
       " 96         97th/100  tensor(1.0614)  1.061411  1.126593       0.0        0.0   \n",
       " 97         98th/100  tensor(1.0627)  1.062703  1.129339       0.0        0.0   \n",
       " 98         99th/100  tensor(1.0618)  1.061791  1.127400       0.0        0.0   \n",
       " 99        100th/100  tensor(1.0526)  1.052623  1.108015       0.0        0.0   \n",
       " \n",
       "      F1  Precision  Recall  Specificity  \n",
       " 0   0.0        0.0     0.0          0.0  \n",
       " 1   0.0        0.0     0.0          0.0  \n",
       " 2   0.0        0.0     0.0          0.0  \n",
       " 3   0.0        0.0     0.0          0.0  \n",
       " 4   0.0        0.0     0.0          0.0  \n",
       " ..  ...        ...     ...          ...  \n",
       " 95  0.0        0.0     0.0          0.0  \n",
       " 96  0.0        0.0     0.0          0.0  \n",
       " 97  0.0        0.0     0.0          0.0  \n",
       " 98  0.0        0.0     0.0          0.0  \n",
       " 99  0.0        0.0     0.0          0.0  \n",
       " \n",
       " [100 rows x 20 columns])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8080\")\n",
    "mlflow.set_experiment(\"origin_text_f4/FM\")\n",
    "\n",
    "mlflow_model_training_validtion_or_testing(X_train, y_train, X_valid, y_valid, \n",
    "                             \"FM\", **FM_params, save_records=True, testing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925f10f5",
   "metadata": {},
   "source": [
    "# AutoInt experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9540b83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoInt\n",
    "# field_dims, embed_dim, atten_embed_dim, num_heads, num_layers, mlp_dims, dropouts, has_residual=True\n",
    "# embed_dim=16, atten_embed_dim=64, num_heads=2, num_layers=3, mlp_dims=(400, 400), dropouts=(0, 0, 0)\n",
    "\n",
    "# Paper:\n",
    "# embed_dim is set to 16, batch size set to 1024\n",
    "# num_head is 2, num_layer(interaction layer) is 3, num of hidden units (interaction layer) is 32\n",
    "# test dropout from 0.1 ~ 0.9\n",
    "# optimizer is Adam\n",
    "# test num_layer(interaction layer) from 0 ~ 4, 1 increase dramaticaly, 1 ~ 4 become stable\n",
    "# test atten_embed_dim 8, 16, 24, 32, movie len is getting better, for KDD12, 24 is best, then decrease\n",
    "# hidden units shape is set to (1, 200) or (4, 100)\n",
    "# residaul is crucial\n",
    "\n",
    "input_dim = len(X_train[0])\n",
    "embedding_size = 768\n",
    "field_num = len(columns_to_train)\n",
    "\n",
    "AutoInt_params = {\n",
    "    'hyperparameters': {\n",
    "        'field_dims': [embedding_size for i in range(field_num)], \n",
    "#         'embed_dim': [768], \n",
    "        'embed_dim': 768, \n",
    "#         'atten_embed_dim': [(64, 32)],\n",
    "#         'atten_embed_dim': [2**i for i in range(2, 7)],\n",
    "        'atten_embed_dim': 32,\n",
    "#         \"num_heads\": [2],\n",
    "        \"num_heads\": 2,\n",
    "#         \"num_layers\": [3],\n",
    "#         \"num_layers\": [i+1 for i in range(5)],\n",
    "        \"num_layers\": 3,\n",
    "#         'mlp_dims': [(16, 16), (400, 400)],\n",
    "#         'mlp_dims': [tuple([size] * num_layers) for num_layers in range(1, 6) for size in [i*100 for i in range(1, 6)]],\n",
    "        'mlp_dims': (256, 256, 256),\n",
    "#         'dropouts': [(0.5, 0.5, 0.5)],\n",
    "#         'dropouts': [tuple([size * 0.1] * 3) for size in range(1, 10)],\n",
    "        'dropouts': (0.0, 0.0, 0.0),\n",
    "        \"has_residual\": True\n",
    "    },\n",
    "    \n",
    "    'task_type': 'Regression', 'loss_type': 'MSE', 'optimizer_type': 'Adam', \n",
    "#         'dl_learning_rate': [0.01, 0.02, 0.001], \n",
    "#     'dl_learning_rate': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1],\n",
    "    'dl_learning_rate': 0.001,\n",
    "#     'epochs_num': [10, 20, 30], \n",
    "    'epochs_num': 100,\n",
    "#         'batch_size': [100, 500, 1000]\n",
    "#     'batch_size': [128, 256, 512, 1024]\n",
    "    'batch_size': 512\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5813a5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/04/08 16:54:10 INFO mlflow.tracking.fluent: Experiment with name 'origin_text_f4/AutoInt' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training AutoInt model ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(              Timestamp Model_name    Training_for AutoInt_field_dims  \\\n",
       " 0   2024-04-08 16:54:10    AutoInt  for_validation         [768, 768]   \n",
       " 1   2024-04-08 16:54:10    AutoInt  for_validation         [768, 768]   \n",
       " 2   2024-04-08 16:54:11    AutoInt  for_validation         [768, 768]   \n",
       " 3   2024-04-08 16:54:11    AutoInt  for_validation         [768, 768]   \n",
       " 4   2024-04-08 16:54:11    AutoInt  for_validation         [768, 768]   \n",
       " ..                  ...        ...             ...                ...   \n",
       " 95  2024-04-08 16:54:44    AutoInt  for_validation         [768, 768]   \n",
       " 96  2024-04-08 16:54:45    AutoInt  for_validation         [768, 768]   \n",
       " 97  2024-04-08 16:54:45    AutoInt  for_validation         [768, 768]   \n",
       " 98  2024-04-08 16:54:45    AutoInt  for_validation         [768, 768]   \n",
       " 99  2024-04-08 16:54:46    AutoInt  for_validation         [768, 768]   \n",
       " \n",
       "     AutoInt_embed_dim  AutoInt_atten_embed_dim  AutoInt_num_heads  \\\n",
       " 0                 768                       32                  2   \n",
       " 1                 768                       32                  2   \n",
       " 2                 768                       32                  2   \n",
       " 3                 768                       32                  2   \n",
       " 4                 768                       32                  2   \n",
       " ..                ...                      ...                ...   \n",
       " 95                768                       32                  2   \n",
       " 96                768                       32                  2   \n",
       " 97                768                       32                  2   \n",
       " 98                768                       32                  2   \n",
       " 99                768                       32                  2   \n",
       " \n",
       "     AutoInt_num_layers AutoInt_mlp_dims AutoInt_dropouts  ...  \\\n",
       " 0                    3  (256, 256, 256)  (0.0, 0.0, 0.0)  ...   \n",
       " 1                    3  (256, 256, 256)  (0.0, 0.0, 0.0)  ...   \n",
       " 2                    3  (256, 256, 256)  (0.0, 0.0, 0.0)  ...   \n",
       " 3                    3  (256, 256, 256)  (0.0, 0.0, 0.0)  ...   \n",
       " 4                    3  (256, 256, 256)  (0.0, 0.0, 0.0)  ...   \n",
       " ..                 ...              ...              ...  ...   \n",
       " 95                   3  (256, 256, 256)  (0.0, 0.0, 0.0)  ...   \n",
       " 96                   3  (256, 256, 256)  (0.0, 0.0, 0.0)  ...   \n",
       " 97                   3  (256, 256, 256)  (0.0, 0.0, 0.0)  ...   \n",
       " 98                   3  (256, 256, 256)  (0.0, 0.0, 0.0)  ...   \n",
       " 99                   3  (256, 256, 256)  (0.0, 0.0, 0.0)  ...   \n",
       " \n",
       "     Epoch/Epochs_num  Avg_Loss  Avg_RMSE   Avg_MSE  Avg_Accuracy  \\\n",
       " 0            1th/100  3.549220  1.668770  3.549220           0.0   \n",
       " 1            2th/100  0.979619  0.986503  0.979619           0.0   \n",
       " 2            3th/100  0.865391  0.929156  0.865391           0.0   \n",
       " 3            4th/100  0.840894  0.916475  0.840894           0.0   \n",
       " 4            5th/100  0.835917  0.913858  0.835917           0.0   \n",
       " ..               ...       ...       ...       ...           ...   \n",
       " 95          96th/100  0.076253  0.274844  0.076253           0.0   \n",
       " 96          97th/100  0.055823  0.235789  0.055823           0.0   \n",
       " 97          98th/100  0.049262  0.220463  0.049262           0.0   \n",
       " 98          99th/100  0.046609  0.215164  0.046609           0.0   \n",
       " 99         100th/100  0.045204  0.211708  0.045204           0.0   \n",
       " \n",
       "     Avg_AUC_score  Avg_F1 Avg_Precision  Avg_Recall  Avg_Specificity  \n",
       " 0             0.0     0.0           0.0         0.0              0.0  \n",
       " 1             0.0     0.0           0.0         0.0              0.0  \n",
       " 2             0.0     0.0           0.0         0.0              0.0  \n",
       " 3             0.0     0.0           0.0         0.0              0.0  \n",
       " 4             0.0     0.0           0.0         0.0              0.0  \n",
       " ..            ...     ...           ...         ...              ...  \n",
       " 95            0.0     0.0           0.0         0.0              0.0  \n",
       " 96            0.0     0.0           0.0         0.0              0.0  \n",
       " 97            0.0     0.0           0.0         0.0              0.0  \n",
       " 98            0.0     0.0           0.0         0.0              0.0  \n",
       " 99            0.0     0.0           0.0         0.0              0.0  \n",
       " \n",
       " [100 rows x 27 columns],\n",
       "               Timestamp Model_name AutoInt_field_dims  AutoInt_embed_dim  \\\n",
       " 0   2024-04-08 16:54:10    AutoInt         [768, 768]                768   \n",
       " 1   2024-04-08 16:54:10    AutoInt         [768, 768]                768   \n",
       " 2   2024-04-08 16:54:11    AutoInt         [768, 768]                768   \n",
       " 3   2024-04-08 16:54:11    AutoInt         [768, 768]                768   \n",
       " 4   2024-04-08 16:54:12    AutoInt         [768, 768]                768   \n",
       " ..                  ...        ...                ...                ...   \n",
       " 95  2024-04-08 16:54:44    AutoInt         [768, 768]                768   \n",
       " 96  2024-04-08 16:54:45    AutoInt         [768, 768]                768   \n",
       " 97  2024-04-08 16:54:45    AutoInt         [768, 768]                768   \n",
       " 98  2024-04-08 16:54:45    AutoInt         [768, 768]                768   \n",
       " 99  2024-04-08 16:54:46    AutoInt         [768, 768]                768   \n",
       " \n",
       "     AutoInt_atten_embed_dim  AutoInt_num_heads  AutoInt_num_layers  \\\n",
       " 0                        32                  2                   3   \n",
       " 1                        32                  2                   3   \n",
       " 2                        32                  2                   3   \n",
       " 3                        32                  2                   3   \n",
       " 4                        32                  2                   3   \n",
       " ..                      ...                ...                 ...   \n",
       " 95                       32                  2                   3   \n",
       " 96                       32                  2                   3   \n",
       " 97                       32                  2                   3   \n",
       " 98                       32                  2                   3   \n",
       " 99                       32                  2                   3   \n",
       " \n",
       "    AutoInt_mlp_dims AutoInt_dropouts  AutoInt_has_residual  ...  \\\n",
       " 0   (256, 256, 256)  (0.0, 0.0, 0.0)                  True  ...   \n",
       " 1   (256, 256, 256)  (0.0, 0.0, 0.0)                  True  ...   \n",
       " 2   (256, 256, 256)  (0.0, 0.0, 0.0)                  True  ...   \n",
       " 3   (256, 256, 256)  (0.0, 0.0, 0.0)                  True  ...   \n",
       " 4   (256, 256, 256)  (0.0, 0.0, 0.0)                  True  ...   \n",
       " ..              ...              ...                   ...  ...   \n",
       " 95  (256, 256, 256)  (0.0, 0.0, 0.0)                  True  ...   \n",
       " 96  (256, 256, 256)  (0.0, 0.0, 0.0)                  True  ...   \n",
       " 97  (256, 256, 256)  (0.0, 0.0, 0.0)                  True  ...   \n",
       " 98  (256, 256, 256)  (0.0, 0.0, 0.0)                  True  ...   \n",
       " 99  (256, 256, 256)  (0.0, 0.0, 0.0)                  True  ...   \n",
       " \n",
       "    Epoch/Epochs_num            Loss      RMSE       MSE  Accuracy  AUC_score  \\\n",
       " 0           1th/100  tensor(1.6090)  1.268452  1.608971       0.0        0.0   \n",
       " 1           2th/100  tensor(0.9280)  0.963332  0.928009       0.0        0.0   \n",
       " 2           3th/100  tensor(0.9254)  0.961965  0.925378       0.0        0.0   \n",
       " 3           4th/100  tensor(0.9570)  0.978251  0.956974       0.0        0.0   \n",
       " 4           5th/100  tensor(0.9402)  0.969646  0.940214       0.0        0.0   \n",
       " ..              ...             ...       ...       ...       ...        ...   \n",
       " 95         96th/100  tensor(1.2664)  1.125350  1.266413       0.0        0.0   \n",
       " 96         97th/100  tensor(1.2630)  1.123826  1.262985       0.0        0.0   \n",
       " 97         98th/100  tensor(1.2912)  1.136308  1.291197       0.0        0.0   \n",
       " 98         99th/100  tensor(1.2750)  1.129143  1.274963       0.0        0.0   \n",
       " 99        100th/100  tensor(1.2837)  1.133020  1.283734       0.0        0.0   \n",
       " \n",
       "      F1 Precision  Recall  Specificity  \n",
       " 0   0.0       0.0     0.0          0.0  \n",
       " 1   0.0       0.0     0.0          0.0  \n",
       " 2   0.0       0.0     0.0          0.0  \n",
       " 3   0.0       0.0     0.0          0.0  \n",
       " 4   0.0       0.0     0.0          0.0  \n",
       " ..  ...       ...     ...          ...  \n",
       " 95  0.0       0.0     0.0          0.0  \n",
       " 96  0.0       0.0     0.0          0.0  \n",
       " 97  0.0       0.0     0.0          0.0  \n",
       " 98  0.0       0.0     0.0          0.0  \n",
       " 99  0.0       0.0     0.0          0.0  \n",
       " \n",
       " [100 rows x 26 columns])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8080\")\n",
    "mlflow.set_experiment(\"origin_text_f4/AutoInt\")\n",
    "\n",
    "mlflow_model_training_validtion_or_testing(X_train, y_train, X_valid, y_valid, \n",
    "                             \"AutoInt\", **AutoInt_params, save_records=True, testing=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
