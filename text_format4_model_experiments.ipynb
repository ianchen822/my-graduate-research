{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bb5ef47",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "322c91ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c69e346",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# data_path = '../Data_preprocessing/'\n",
    "training_data_path = 'research_training_set_with_concatenated_reviews_business_categories_and_feature_vectors.csv'\n",
    "training_data = pd.read_csv(training_data_path)\n",
    "# training_data.head()\n",
    "\n",
    "# data_path = '../Data_preprocessing/'\n",
    "validation_data_path = 'research_validation_set_with_concatenated_reviews_business_categories_and_feature_vectors.csv'\n",
    "validation_data = pd.read_csv(validation_data_path)\n",
    "# validation_data.head()\n",
    "\n",
    "# data_path = '../Data_preprocessing/'\n",
    "test_data_path = 'research_test_set_with_concatenated_reviews_business_categories_and_feature_vectors.csv'\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "# test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4a461ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['user_feature_vector', 'business_feature_vector']\n"
     ]
    }
   ],
   "source": [
    "# Training and Validation Data preprocessing\n",
    "\n",
    "training_data_cols = list(training_data.columns)\n",
    "columns_to_train = [col for col in training_data_cols if \"vector\" in col.lower()]\n",
    "print(columns_to_train)\n",
    "\n",
    "# columns_to_train = ['user_feature_vector', 'business_feature_vector']\n",
    "# columns_to_train = ['user_feature_vector', 'business_feature_vector', \"business_categories_feature_vector\"]\n",
    "\n",
    "concatenated_vectors = []\n",
    "for i in range(len(training_data)):\n",
    "    col_vectors = []\n",
    "    for col in columns_to_train:\n",
    "        col_vectors.append(np.array(eval(training_data[col][i])))\n",
    "    concatenated_vector = np.concatenate(col_vectors)\n",
    "    concatenated_vectors.append(concatenated_vector)\n",
    "\n",
    "X_train = np.array(concatenated_vectors)\n",
    "y_train = np.array(training_data['stars'])\n",
    "\n",
    "concatenated_vectors = []\n",
    "for i in range(len(validation_data)):\n",
    "    col_vectors = []\n",
    "    for col in columns_to_train:\n",
    "        col_vectors.append(np.array(eval(validation_data[col][i])))\n",
    "    concatenated_vector = np.concatenate(col_vectors)\n",
    "    concatenated_vectors.append(concatenated_vector)\n",
    "\n",
    "X_valid = np.array(concatenated_vectors)\n",
    "y_valid = np.array(validation_data['stars'])\n",
    "\n",
    "concatenated_vectors = []\n",
    "for i in range(len(test_data)):\n",
    "    col_vectors = []\n",
    "    for col in columns_to_train:\n",
    "        col_vectors.append(np.array(eval(test_data[col][i])))\n",
    "    concatenated_vector = np.concatenate(col_vectors)\n",
    "    concatenated_vectors.append(concatenated_vector)\n",
    "\n",
    "X_test = np.array(concatenated_vectors)\n",
    "y_test = np.array(test_data['stars'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e00263",
   "metadata": {},
   "source": [
    "# Load written code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afc53292",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import nbformat\n",
    "\n",
    "def load_notebook(notebook_path):\n",
    "    with open(notebook_path, 'r', encoding='utf-8') as f:\n",
    "        nb = nbformat.read(f, as_version=4)\n",
    "    code_cells = [cell.source for cell in nb.cells if cell.cell_type == 'code']\n",
    "    exec('\\n'.join(code_cells), globals())\n",
    "\n",
    "# import written function and variable\n",
    "\n",
    "parent_directory = Path('../../../../')\n",
    "# parent_directory = Path('../../')\n",
    "model_zoo_path = parent_directory / 'model_zoo.ipynb'\n",
    "model_training_validation_testing_function_path = parent_directory / 'model_train_val_test_function.ipynb'\n",
    "# model_training_validation_params_path = parent_directory / 'model_train_val_params.ipynb'\n",
    "\n",
    "load_notebook(model_zoo_path)\n",
    "load_notebook(model_training_validation_testing_function_path)\n",
    "# load_notebook(model_training_validation_params_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed13138f",
   "metadata": {},
   "source": [
    "# FM experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9e5988",
   "metadata": {},
   "source": [
    "Training, Validating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "065dde5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(X_train[0])\n",
    "embedding_size = 768\n",
    "field_num = len(columns_to_train)\n",
    "\n",
    "FM_params = {\n",
    "    'hyperparameters': {\n",
    "        'input_dim': input_dim, \n",
    "#         'factors_num': [5, 10, 15],\n",
    "#         'factors_num': [i+1 for i in range(20)]\n",
    "#         'factors_num': [5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "#         'factors_num': [2**i for i in range(3, 7)],\n",
    "        'factors_num': 8\n",
    "    },\n",
    "    \n",
    "    'task_type': 'Regression', 'loss_type': 'MSE', 'optimizer_type': 'Adam', \n",
    "#   'dl_learning_rate': [0.01, 0.02, 0.001], \n",
    "    'dl_learning_rate': 0.001,\n",
    "    'epochs_num': 100, \n",
    "#   'batch_size': [100, 500, 1000]\n",
    "    'batch_size': 512\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e062d572",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/04/13 02:29:21 INFO mlflow.tracking.fluent: Experiment with name 'ori_f4_bbs_tv/FM' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training FM model ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/mlflow/types/utils.py:393: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(              Timestamp Model_name    Training_for  FM_input_dim  \\\n",
       " 0   2024-04-13 02:29:22         FM  for_validation          1536   \n",
       " 1   2024-04-13 02:29:22         FM  for_validation          1536   \n",
       " 2   2024-04-13 02:29:22         FM  for_validation          1536   \n",
       " 3   2024-04-13 02:29:23         FM  for_validation          1536   \n",
       " 4   2024-04-13 02:29:23         FM  for_validation          1536   \n",
       " ..                  ...        ...             ...           ...   \n",
       " 95  2024-04-13 02:29:37         FM  for_validation          1536   \n",
       " 96  2024-04-13 02:29:37         FM  for_validation          1536   \n",
       " 97  2024-04-13 02:29:37         FM  for_validation          1536   \n",
       " 98  2024-04-13 02:29:37         FM  for_validation          1536   \n",
       " 99  2024-04-13 02:29:37         FM  for_validation          1536   \n",
       " \n",
       "     FM_factors_num   Task_type Loss_type Optimizer_type  DL_learning_rate  \\\n",
       " 0                8  Regression       MSE           Adam             0.001   \n",
       " 1                8  Regression       MSE           Adam             0.001   \n",
       " 2                8  Regression       MSE           Adam             0.001   \n",
       " 3                8  Regression       MSE           Adam             0.001   \n",
       " 4                8  Regression       MSE           Adam             0.001   \n",
       " ..             ...         ...       ...            ...               ...   \n",
       " 95               8  Regression       MSE           Adam             0.001   \n",
       " 96               8  Regression       MSE           Adam             0.001   \n",
       " 97               8  Regression       MSE           Adam             0.001   \n",
       " 98               8  Regression       MSE           Adam             0.001   \n",
       " 99               8  Regression       MSE           Adam             0.001   \n",
       " \n",
       "     Epochs_num  ...  Epoch/Epochs_num  Avg_Loss  Avg_RMSE   Avg_MSE  \\\n",
       " 0          100  ...           1th/100  2.153149  1.416318  2.153149   \n",
       " 1          100  ...           2th/100  1.258179  1.119791  1.258179   \n",
       " 2          100  ...           3th/100  1.038278  1.018336  1.038278   \n",
       " 3          100  ...           4th/100  0.949258  0.973698  0.949258   \n",
       " 4          100  ...           5th/100  0.912151  0.954543  0.912151   \n",
       " ..         ...  ...               ...       ...       ...       ...   \n",
       " 95         100  ...          96th/100  0.522165  0.722247  0.522165   \n",
       " 96         100  ...          97th/100  0.520799  0.721287  0.520799   \n",
       " 97         100  ...          98th/100  0.518426  0.719499  0.518426   \n",
       " 98         100  ...          99th/100  0.519043  0.719902  0.519043   \n",
       " 99         100  ...         100th/100  0.519071  0.720043  0.519071   \n",
       " \n",
       "     Avg_Accuracy  Avg_AUC_score  Avg_F1  Avg_Precision  Avg_Recall  \\\n",
       " 0            0.0            0.0     0.0            0.0         0.0   \n",
       " 1            0.0            0.0     0.0            0.0         0.0   \n",
       " 2            0.0            0.0     0.0            0.0         0.0   \n",
       " 3            0.0            0.0     0.0            0.0         0.0   \n",
       " 4            0.0            0.0     0.0            0.0         0.0   \n",
       " ..           ...            ...     ...            ...         ...   \n",
       " 95           0.0            0.0     0.0            0.0         0.0   \n",
       " 96           0.0            0.0     0.0            0.0         0.0   \n",
       " 97           0.0            0.0     0.0            0.0         0.0   \n",
       " 98           0.0            0.0     0.0            0.0         0.0   \n",
       " 99           0.0            0.0     0.0            0.0         0.0   \n",
       " \n",
       "     Avg_Specificity  \n",
       " 0               0.0  \n",
       " 1               0.0  \n",
       " 2               0.0  \n",
       " 3               0.0  \n",
       " 4               0.0  \n",
       " ..              ...  \n",
       " 95              0.0  \n",
       " 96              0.0  \n",
       " 97              0.0  \n",
       " 98              0.0  \n",
       " 99              0.0  \n",
       " \n",
       " [100 rows x 21 columns],\n",
       "               Timestamp Model_name  FM_input_dim  FM_factors_num   Task_type  \\\n",
       " 0   2024-04-13 02:29:22         FM          1536               8  Regression   \n",
       " 1   2024-04-13 02:29:22         FM          1536               8  Regression   \n",
       " 2   2024-04-13 02:29:22         FM          1536               8  Regression   \n",
       " 3   2024-04-13 02:29:23         FM          1536               8  Regression   \n",
       " 4   2024-04-13 02:29:23         FM          1536               8  Regression   \n",
       " ..                  ...        ...           ...             ...         ...   \n",
       " 95  2024-04-13 02:29:37         FM          1536               8  Regression   \n",
       " 96  2024-04-13 02:29:37         FM          1536               8  Regression   \n",
       " 97  2024-04-13 02:29:37         FM          1536               8  Regression   \n",
       " 98  2024-04-13 02:29:37         FM          1536               8  Regression   \n",
       " 99  2024-04-13 02:29:37         FM          1536               8  Regression   \n",
       " \n",
       "    Loss_type Optimizer_type  DL_learning_rate  Epochs_num  Batch_size  \\\n",
       " 0        MSE           Adam             0.001         100         512   \n",
       " 1        MSE           Adam             0.001         100         512   \n",
       " 2        MSE           Adam             0.001         100         512   \n",
       " 3        MSE           Adam             0.001         100         512   \n",
       " 4        MSE           Adam             0.001         100         512   \n",
       " ..       ...            ...               ...         ...         ...   \n",
       " 95       MSE           Adam             0.001         100         512   \n",
       " 96       MSE           Adam             0.001         100         512   \n",
       " 97       MSE           Adam             0.001         100         512   \n",
       " 98       MSE           Adam             0.001         100         512   \n",
       " 99       MSE           Adam             0.001         100         512   \n",
       " \n",
       "    Epoch/Epochs_num            Loss      RMSE       MSE  Accuracy  AUC_score  \\\n",
       " 0           1th/100  tensor(1.4565)  1.206849  1.456484       0.0        0.0   \n",
       " 1           2th/100  tensor(1.1830)  1.087652  1.182987       0.0        0.0   \n",
       " 2           3th/100  tensor(1.0619)  1.030493  1.061916       0.0        0.0   \n",
       " 3           4th/100  tensor(1.0026)  1.001279  1.002560       0.0        0.0   \n",
       " 4           5th/100  tensor(0.9799)  0.989876  0.979854       0.0        0.0   \n",
       " ..              ...             ...       ...       ...       ...        ...   \n",
       " 95         96th/100  tensor(1.0146)  1.007271  1.014595       0.0        0.0   \n",
       " 96         97th/100  tensor(1.0242)  1.012011  1.024166       0.0        0.0   \n",
       " 97         98th/100  tensor(1.0169)  1.008417  1.016906       0.0        0.0   \n",
       " 98         99th/100  tensor(1.0509)  1.025142  1.050917       0.0        0.0   \n",
       " 99        100th/100  tensor(1.0248)  1.012336  1.024825       0.0        0.0   \n",
       " \n",
       "      F1  Precision  Recall  Specificity  \n",
       " 0   0.0        0.0     0.0          0.0  \n",
       " 1   0.0        0.0     0.0          0.0  \n",
       " 2   0.0        0.0     0.0          0.0  \n",
       " 3   0.0        0.0     0.0          0.0  \n",
       " 4   0.0        0.0     0.0          0.0  \n",
       " ..  ...        ...     ...          ...  \n",
       " 95  0.0        0.0     0.0          0.0  \n",
       " 96  0.0        0.0     0.0          0.0  \n",
       " 97  0.0        0.0     0.0          0.0  \n",
       " 98  0.0        0.0     0.0          0.0  \n",
       " 99  0.0        0.0     0.0          0.0  \n",
       " \n",
       " [100 rows x 20 columns])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training and validating\n",
    "\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8080\")\n",
    "mlflow.set_experiment(\"ori_f4_bbs_tv/FM\")\n",
    "\n",
    "mlflow_model_training_validtion_or_testing(X_train, y_train, X_valid, y_valid, \n",
    "                             \"FM\", **FM_params, save_records=True, testing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6fb15ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Specify the directory containing the MLmodel file\n",
    "# model_dir = \"runs:/b63baa1aa6894b328ba64a2d8abc3f2e/FM_model\"\n",
    "\n",
    "# # Load the PyTorch model from the specified directory\n",
    "# model = mlflow.pytorch.load_model(model_dir)\n",
    "\n",
    "# # Get the state dictionary\n",
    "# state_dict = model.state_dict()\n",
    "\n",
    "# print(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b6cd9e",
   "metadata": {},
   "source": [
    "Training, Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "836adf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(X_train[0])\n",
    "embedding_size = 768\n",
    "field_num = len(columns_to_train)\n",
    "\n",
    "test_FM_params = {\n",
    "    'hyperparameters': {\n",
    "        'input_dim': input_dim, \n",
    "        'factors_num': 8\n",
    "    },\n",
    "    \n",
    "    'task_type': 'Regression', 'loss_type': 'MSE', 'optimizer_type': 'Adam', \n",
    "    'dl_learning_rate': 0.001,\n",
    "    'epochs_num': 100, \n",
    "    'batch_size': 512\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55c7ba77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/04/13 02:29:40 INFO mlflow.tracking.fluent: Experiment with name 'ori_f4_bbs_tt/FM' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training FM model ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/mlflow/types/utils.py:393: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(              Timestamp Model_name Training_for  FM_input_dim  FM_factors_num  \\\n",
       " 0   2024-04-13 02:29:40         FM  for_testing          1536               8   \n",
       " 1   2024-04-13 02:29:40         FM  for_testing          1536               8   \n",
       " 2   2024-04-13 02:29:40         FM  for_testing          1536               8   \n",
       " 3   2024-04-13 02:29:40         FM  for_testing          1536               8   \n",
       " 4   2024-04-13 02:29:41         FM  for_testing          1536               8   \n",
       " ..                  ...        ...          ...           ...             ...   \n",
       " 95  2024-04-13 02:29:56         FM  for_testing          1536               8   \n",
       " 96  2024-04-13 02:29:56         FM  for_testing          1536               8   \n",
       " 97  2024-04-13 02:29:56         FM  for_testing          1536               8   \n",
       " 98  2024-04-13 02:29:56         FM  for_testing          1536               8   \n",
       " 99  2024-04-13 02:29:56         FM  for_testing          1536               8   \n",
       " \n",
       "      Task_type Loss_type Optimizer_type  DL_learning_rate  Epochs_num  ...  \\\n",
       " 0   Regression       MSE           Adam             0.001         100  ...   \n",
       " 1   Regression       MSE           Adam             0.001         100  ...   \n",
       " 2   Regression       MSE           Adam             0.001         100  ...   \n",
       " 3   Regression       MSE           Adam             0.001         100  ...   \n",
       " 4   Regression       MSE           Adam             0.001         100  ...   \n",
       " ..         ...       ...            ...               ...         ...  ...   \n",
       " 95  Regression       MSE           Adam             0.001         100  ...   \n",
       " 96  Regression       MSE           Adam             0.001         100  ...   \n",
       " 97  Regression       MSE           Adam             0.001         100  ...   \n",
       " 98  Regression       MSE           Adam             0.001         100  ...   \n",
       " 99  Regression       MSE           Adam             0.001         100  ...   \n",
       " \n",
       "     Epoch/Epochs_num  Avg_Loss  Avg_RMSE   Avg_MSE  Avg_Accuracy  \\\n",
       " 0            1th/100  4.483729  1.838421  4.483729           0.0   \n",
       " 1            2th/100  1.684713  1.295871  1.684713           0.0   \n",
       " 2            3th/100  1.345972  1.159501  1.345972           0.0   \n",
       " 3            4th/100  1.207610  1.098147  1.207610           0.0   \n",
       " 4            5th/100  1.121386  1.058138  1.121386           0.0   \n",
       " ..               ...       ...       ...       ...           ...   \n",
       " 95          96th/100  0.605653  0.777591  0.605653           0.0   \n",
       " 96          97th/100  0.600678  0.774570  0.600678           0.0   \n",
       " 97          98th/100  0.597183  0.772120  0.597183           0.0   \n",
       " 98          99th/100  0.597536  0.772610  0.597536           0.0   \n",
       " 99         100th/100  0.590571  0.768258  0.590571           0.0   \n",
       " \n",
       "     Avg_AUC_score  Avg_F1  Avg_Precision  Avg_Recall  Avg_Specificity  \n",
       " 0             0.0     0.0            0.0         0.0              0.0  \n",
       " 1             0.0     0.0            0.0         0.0              0.0  \n",
       " 2             0.0     0.0            0.0         0.0              0.0  \n",
       " 3             0.0     0.0            0.0         0.0              0.0  \n",
       " 4             0.0     0.0            0.0         0.0              0.0  \n",
       " ..            ...     ...            ...         ...              ...  \n",
       " 95            0.0     0.0            0.0         0.0              0.0  \n",
       " 96            0.0     0.0            0.0         0.0              0.0  \n",
       " 97            0.0     0.0            0.0         0.0              0.0  \n",
       " 98            0.0     0.0            0.0         0.0              0.0  \n",
       " 99            0.0     0.0            0.0         0.0              0.0  \n",
       " \n",
       " [100 rows x 21 columns],\n",
       "               Timestamp Model_name  FM_input_dim  FM_factors_num   Task_type  \\\n",
       " 0   2024-04-13 02:29:40         FM          1536               8  Regression   \n",
       " 1   2024-04-13 02:29:40         FM          1536               8  Regression   \n",
       " 2   2024-04-13 02:29:40         FM          1536               8  Regression   \n",
       " 3   2024-04-13 02:29:40         FM          1536               8  Regression   \n",
       " 4   2024-04-13 02:29:41         FM          1536               8  Regression   \n",
       " ..                  ...        ...           ...             ...         ...   \n",
       " 95  2024-04-13 02:29:56         FM          1536               8  Regression   \n",
       " 96  2024-04-13 02:29:56         FM          1536               8  Regression   \n",
       " 97  2024-04-13 02:29:56         FM          1536               8  Regression   \n",
       " 98  2024-04-13 02:29:56         FM          1536               8  Regression   \n",
       " 99  2024-04-13 02:29:56         FM          1536               8  Regression   \n",
       " \n",
       "    Loss_type Optimizer_type  DL_learning_rate  Epochs_num  Batch_size  \\\n",
       " 0        MSE           Adam             0.001         100         512   \n",
       " 1        MSE           Adam             0.001         100         512   \n",
       " 2        MSE           Adam             0.001         100         512   \n",
       " 3        MSE           Adam             0.001         100         512   \n",
       " 4        MSE           Adam             0.001         100         512   \n",
       " ..       ...            ...               ...         ...         ...   \n",
       " 95       MSE           Adam             0.001         100         512   \n",
       " 96       MSE           Adam             0.001         100         512   \n",
       " 97       MSE           Adam             0.001         100         512   \n",
       " 98       MSE           Adam             0.001         100         512   \n",
       " 99       MSE           Adam             0.001         100         512   \n",
       " \n",
       "    Epoch/Epochs_num            Loss      RMSE       MSE  Accuracy  AUC_score  \\\n",
       " 0           1th/100  tensor(1.9746)  1.405217  1.974634       0.0        0.0   \n",
       " 1           2th/100  tensor(1.4409)  1.200380  1.440912       0.0        0.0   \n",
       " 2           3th/100  tensor(1.2695)  1.126733  1.269527       0.0        0.0   \n",
       " 3           4th/100  tensor(1.1752)  1.084081  1.175231       0.0        0.0   \n",
       " 4           5th/100  tensor(1.1130)  1.055001  1.113028       0.0        0.0   \n",
       " ..              ...             ...       ...       ...       ...        ...   \n",
       " 95         96th/100  tensor(0.9670)  0.983383  0.967041       0.0        0.0   \n",
       " 96         97th/100  tensor(0.9560)  0.977753  0.956000       0.0        0.0   \n",
       " 97         98th/100  tensor(0.9506)  0.974988  0.950601       0.0        0.0   \n",
       " 98         99th/100  tensor(0.9585)  0.979018  0.958477       0.0        0.0   \n",
       " 99        100th/100  tensor(0.9525)  0.975966  0.952509       0.0        0.0   \n",
       " \n",
       "      F1  Precision  Recall  Specificity  \n",
       " 0   0.0        0.0     0.0          0.0  \n",
       " 1   0.0        0.0     0.0          0.0  \n",
       " 2   0.0        0.0     0.0          0.0  \n",
       " 3   0.0        0.0     0.0          0.0  \n",
       " 4   0.0        0.0     0.0          0.0  \n",
       " ..  ...        ...     ...          ...  \n",
       " 95  0.0        0.0     0.0          0.0  \n",
       " 96  0.0        0.0     0.0          0.0  \n",
       " 97  0.0        0.0     0.0          0.0  \n",
       " 98  0.0        0.0     0.0          0.0  \n",
       " 99  0.0        0.0     0.0          0.0  \n",
       " \n",
       " [100 rows x 20 columns])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training and testing\n",
    "\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8080\")\n",
    "mlflow.set_experiment(\"ori_f4_bbs_tt/FM\")\n",
    "\n",
    "mlflow_model_training_validtion_or_testing(X_train, y_train, X_test, y_test, \n",
    "                             \"FM\", **test_FM_params, save_records=True, testing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3032e355",
   "metadata": {},
   "source": [
    "# AutoInt experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad20b6be",
   "metadata": {},
   "source": [
    "Training, Validating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cb03cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoInt\n",
    "# field_dims, embed_dim, atten_embed_dim, num_heads, num_layers, mlp_dims, dropouts, has_residual=True\n",
    "# embed_dim=16, atten_embed_dim=64, num_heads=2, num_layers=3, mlp_dims=(400, 400), dropouts=(0, 0, 0)\n",
    "\n",
    "# Paper:\n",
    "# embed_dim is set to 16, batch size set to 1024\n",
    "# num_head is 2, num_layer(interaction layer) is 3, num of hidden units (interaction layer) is 32\n",
    "# test dropout from 0.1 ~ 0.9\n",
    "# optimizer is Adam\n",
    "# test num_layer(interaction layer) from 0 ~ 4, 1 increase dramaticaly, 1 ~ 4 become stable\n",
    "# test atten_embed_dim 8, 16, 24, 32, movie len is getting better, for KDD12, 24 is best, then decrease\n",
    "# hidden units shape is set to (1, 200) or (4, 100)\n",
    "# residaul is crucial\n",
    "\n",
    "input_dim = len(X_train[0])\n",
    "embedding_size = 768\n",
    "field_num = len(columns_to_train)\n",
    "\n",
    "AutoInt_params = {\n",
    "    'hyperparameters': {\n",
    "        'field_dims': [embedding_size for i in range(field_num)], \n",
    "#         'embed_dim': [768], \n",
    "        'embed_dim': 768, \n",
    "#         'atten_embed_dim': [(64, 32)],\n",
    "#         'atten_embed_dim': [2**i for i in range(2, 7)],\n",
    "        'atten_embed_dim': 32,\n",
    "#         \"num_heads\": [2],\n",
    "        \"num_heads\": 2,\n",
    "#         \"num_layers\": [3],\n",
    "#         \"num_layers\": [i+1 for i in range(5)],\n",
    "        \"num_layers\": 3,\n",
    "#         'mlp_dims': [(16, 16), (400, 400)],\n",
    "#         'mlp_dims': [tuple([size] * num_layers) for num_layers in range(1, 6) for size in [i*100 for i in range(1, 6)]],\n",
    "        'mlp_dims': (256, 256, 256),\n",
    "#         'dropouts': [(0.5, 0.5, 0.5)],\n",
    "#         'dropouts': [tuple([size * 0.1] * 3) for size in range(1, 10)],\n",
    "#         'dropouts': (0.0, 0.0, 0.0),\n",
    "        'dropouts': (0.5, 0.5, 0.5),\n",
    "        \"has_residual\": True\n",
    "    },\n",
    "    \n",
    "    'task_type': 'Regression', 'loss_type': 'MSE', 'optimizer_type': 'Adam', \n",
    "#         'dl_learning_rate': [0.01, 0.02, 0.001], \n",
    "#     'dl_learning_rate': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1],\n",
    "    'dl_learning_rate': 0.001,\n",
    "#     'epochs_num': [10, 20, 30], \n",
    "    'epochs_num': 100,\n",
    "#         'batch_size': [100, 500, 1000]\n",
    "#     'batch_size': [128, 256, 512, 1024]\n",
    "    'batch_size': 512\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90301914",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/04/13 02:29:58 INFO mlflow.tracking.fluent: Experiment with name 'ori_f4_bbs_tv/AutoInt' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training AutoInt model ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/mlflow/types/utils.py:393: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(              Timestamp Model_name    Training_for AutoInt_field_dims  \\\n",
       " 0   2024-04-13 02:29:59    AutoInt  for_validation         [768, 768]   \n",
       " 1   2024-04-13 02:29:59    AutoInt  for_validation         [768, 768]   \n",
       " 2   2024-04-13 02:29:59    AutoInt  for_validation         [768, 768]   \n",
       " 3   2024-04-13 02:30:00    AutoInt  for_validation         [768, 768]   \n",
       " 4   2024-04-13 02:30:00    AutoInt  for_validation         [768, 768]   \n",
       " ..                  ...        ...             ...                ...   \n",
       " 95  2024-04-13 02:30:37    AutoInt  for_validation         [768, 768]   \n",
       " 96  2024-04-13 02:30:37    AutoInt  for_validation         [768, 768]   \n",
       " 97  2024-04-13 02:30:37    AutoInt  for_validation         [768, 768]   \n",
       " 98  2024-04-13 02:30:38    AutoInt  for_validation         [768, 768]   \n",
       " 99  2024-04-13 02:30:38    AutoInt  for_validation         [768, 768]   \n",
       " \n",
       "     AutoInt_embed_dim  AutoInt_atten_embed_dim  AutoInt_num_heads  \\\n",
       " 0                 768                       32                  2   \n",
       " 1                 768                       32                  2   \n",
       " 2                 768                       32                  2   \n",
       " 3                 768                       32                  2   \n",
       " 4                 768                       32                  2   \n",
       " ..                ...                      ...                ...   \n",
       " 95                768                       32                  2   \n",
       " 96                768                       32                  2   \n",
       " 97                768                       32                  2   \n",
       " 98                768                       32                  2   \n",
       " 99                768                       32                  2   \n",
       " \n",
       "     AutoInt_num_layers AutoInt_mlp_dims AutoInt_dropouts  ...  \\\n",
       " 0                    3  (256, 256, 256)  (0.5, 0.5, 0.5)  ...   \n",
       " 1                    3  (256, 256, 256)  (0.5, 0.5, 0.5)  ...   \n",
       " 2                    3  (256, 256, 256)  (0.5, 0.5, 0.5)  ...   \n",
       " 3                    3  (256, 256, 256)  (0.5, 0.5, 0.5)  ...   \n",
       " 4                    3  (256, 256, 256)  (0.5, 0.5, 0.5)  ...   \n",
       " ..                 ...              ...              ...  ...   \n",
       " 95                   3  (256, 256, 256)  (0.5, 0.5, 0.5)  ...   \n",
       " 96                   3  (256, 256, 256)  (0.5, 0.5, 0.5)  ...   \n",
       " 97                   3  (256, 256, 256)  (0.5, 0.5, 0.5)  ...   \n",
       " 98                   3  (256, 256, 256)  (0.5, 0.5, 0.5)  ...   \n",
       " 99                   3  (256, 256, 256)  (0.5, 0.5, 0.5)  ...   \n",
       " \n",
       "     Epoch/Epochs_num  Avg_Loss  Avg_RMSE   Avg_MSE  Avg_Accuracy  \\\n",
       " 0            1th/100  3.888137  1.772045  3.888137           0.0   \n",
       " 1            2th/100  0.977348  0.986936  0.977348           0.0   \n",
       " 2            3th/100  0.896616  0.946217  0.896616           0.0   \n",
       " 3            4th/100  0.856692  0.925069  0.856692           0.0   \n",
       " 4            5th/100  0.835099  0.913345  0.835099           0.0   \n",
       " ..               ...       ...       ...       ...           ...   \n",
       " 95          96th/100  0.132906  0.363761  0.132906           0.0   \n",
       " 96          97th/100  0.124199  0.352089  0.124199           0.0   \n",
       " 97          98th/100  0.109171  0.330134  0.109171           0.0   \n",
       " 98          99th/100  0.101222  0.317634  0.101222           0.0   \n",
       " 99         100th/100  0.097330  0.311634  0.097330           0.0   \n",
       " \n",
       "     Avg_AUC_score  Avg_F1 Avg_Precision  Avg_Recall  Avg_Specificity  \n",
       " 0             0.0     0.0           0.0         0.0              0.0  \n",
       " 1             0.0     0.0           0.0         0.0              0.0  \n",
       " 2             0.0     0.0           0.0         0.0              0.0  \n",
       " 3             0.0     0.0           0.0         0.0              0.0  \n",
       " 4             0.0     0.0           0.0         0.0              0.0  \n",
       " ..            ...     ...           ...         ...              ...  \n",
       " 95            0.0     0.0           0.0         0.0              0.0  \n",
       " 96            0.0     0.0           0.0         0.0              0.0  \n",
       " 97            0.0     0.0           0.0         0.0              0.0  \n",
       " 98            0.0     0.0           0.0         0.0              0.0  \n",
       " 99            0.0     0.0           0.0         0.0              0.0  \n",
       " \n",
       " [100 rows x 27 columns],\n",
       "               Timestamp Model_name AutoInt_field_dims  AutoInt_embed_dim  \\\n",
       " 0   2024-04-13 02:29:59    AutoInt         [768, 768]                768   \n",
       " 1   2024-04-13 02:29:59    AutoInt         [768, 768]                768   \n",
       " 2   2024-04-13 02:29:59    AutoInt         [768, 768]                768   \n",
       " 3   2024-04-13 02:30:00    AutoInt         [768, 768]                768   \n",
       " 4   2024-04-13 02:30:00    AutoInt         [768, 768]                768   \n",
       " ..                  ...        ...                ...                ...   \n",
       " 95  2024-04-13 02:30:37    AutoInt         [768, 768]                768   \n",
       " 96  2024-04-13 02:30:37    AutoInt         [768, 768]                768   \n",
       " 97  2024-04-13 02:30:37    AutoInt         [768, 768]                768   \n",
       " 98  2024-04-13 02:30:38    AutoInt         [768, 768]                768   \n",
       " 99  2024-04-13 02:30:38    AutoInt         [768, 768]                768   \n",
       " \n",
       "     AutoInt_atten_embed_dim  AutoInt_num_heads  AutoInt_num_layers  \\\n",
       " 0                        32                  2                   3   \n",
       " 1                        32                  2                   3   \n",
       " 2                        32                  2                   3   \n",
       " 3                        32                  2                   3   \n",
       " 4                        32                  2                   3   \n",
       " ..                      ...                ...                 ...   \n",
       " 95                       32                  2                   3   \n",
       " 96                       32                  2                   3   \n",
       " 97                       32                  2                   3   \n",
       " 98                       32                  2                   3   \n",
       " 99                       32                  2                   3   \n",
       " \n",
       "    AutoInt_mlp_dims AutoInt_dropouts  AutoInt_has_residual  ...  \\\n",
       " 0   (256, 256, 256)  (0.5, 0.5, 0.5)                  True  ...   \n",
       " 1   (256, 256, 256)  (0.5, 0.5, 0.5)                  True  ...   \n",
       " 2   (256, 256, 256)  (0.5, 0.5, 0.5)                  True  ...   \n",
       " 3   (256, 256, 256)  (0.5, 0.5, 0.5)                  True  ...   \n",
       " 4   (256, 256, 256)  (0.5, 0.5, 0.5)                  True  ...   \n",
       " ..              ...              ...                   ...  ...   \n",
       " 95  (256, 256, 256)  (0.5, 0.5, 0.5)                  True  ...   \n",
       " 96  (256, 256, 256)  (0.5, 0.5, 0.5)                  True  ...   \n",
       " 97  (256, 256, 256)  (0.5, 0.5, 0.5)                  True  ...   \n",
       " 98  (256, 256, 256)  (0.5, 0.5, 0.5)                  True  ...   \n",
       " 99  (256, 256, 256)  (0.5, 0.5, 0.5)                  True  ...   \n",
       " \n",
       "    Epoch/Epochs_num            Loss      RMSE       MSE  Accuracy  AUC_score  \\\n",
       " 0           1th/100  tensor(1.1159)  1.056377  1.115933       0.0        0.0   \n",
       " 1           2th/100  tensor(1.0322)  1.015978  1.032212       0.0        0.0   \n",
       " 2           3th/100  tensor(0.9397)  0.969386  0.939709       0.0        0.0   \n",
       " 3           4th/100  tensor(0.9300)  0.964390  0.930048       0.0        0.0   \n",
       " 4           5th/100  tensor(0.9395)  0.969258  0.939462       0.0        0.0   \n",
       " ..              ...             ...       ...       ...       ...        ...   \n",
       " 95         96th/100  tensor(1.2030)  1.096801  1.202973       0.0        0.0   \n",
       " 96         97th/100  tensor(1.2330)  1.110384  1.232954       0.0        0.0   \n",
       " 97         98th/100  tensor(1.1693)  1.081350  1.169318       0.0        0.0   \n",
       " 98         99th/100  tensor(1.1716)  1.082424  1.171642       0.0        0.0   \n",
       " 99        100th/100  tensor(1.2286)  1.108430  1.228618       0.0        0.0   \n",
       " \n",
       "      F1 Precision  Recall  Specificity  \n",
       " 0   0.0       0.0     0.0          0.0  \n",
       " 1   0.0       0.0     0.0          0.0  \n",
       " 2   0.0       0.0     0.0          0.0  \n",
       " 3   0.0       0.0     0.0          0.0  \n",
       " 4   0.0       0.0     0.0          0.0  \n",
       " ..  ...       ...     ...          ...  \n",
       " 95  0.0       0.0     0.0          0.0  \n",
       " 96  0.0       0.0     0.0          0.0  \n",
       " 97  0.0       0.0     0.0          0.0  \n",
       " 98  0.0       0.0     0.0          0.0  \n",
       " 99  0.0       0.0     0.0          0.0  \n",
       " \n",
       " [100 rows x 26 columns])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training and validating\n",
    "\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8080\")\n",
    "mlflow.set_experiment(\"ori_f4_bbs_tv/AutoInt\")\n",
    "\n",
    "mlflow_model_training_validtion_or_testing(X_train, y_train, X_valid, y_valid, \n",
    "                             \"AutoInt\", **AutoInt_params, save_records=True, testing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39276da5",
   "metadata": {},
   "source": [
    "Training, Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34b37130",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(X_train[0])\n",
    "embedding_size = 768\n",
    "field_num = len(columns_to_train)\n",
    "\n",
    "test_AutoInt_params = {\n",
    "    'hyperparameters': {\n",
    "        'field_dims': [embedding_size for i in range(field_num)], \n",
    "        'embed_dim': 768, \n",
    "        'atten_embed_dim': 32,\n",
    "        \"num_heads\": 2,\n",
    "        \"num_layers\": 3,\n",
    "        'mlp_dims': (256, 256, 256),\n",
    "        'dropouts': (0.5, 0.5, 0.5),\n",
    "        \"has_residual\": True\n",
    "    },\n",
    "    \n",
    "    'task_type': 'Regression', 'loss_type': 'MSE', 'optimizer_type': 'Adam', \n",
    "    'dl_learning_rate': 0.001,\n",
    "    'epochs_num': 100,\n",
    "    'batch_size': 512\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4178dfd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/04/13 02:30:40 INFO mlflow.tracking.fluent: Experiment with name 'ori_f4_bbs_tt/AutoInt' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training AutoInt model ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/mlflow/types/utils.py:393: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(              Timestamp Model_name Training_for AutoInt_field_dims  \\\n",
       " 0   2024-04-13 02:30:41    AutoInt  for_testing         [768, 768]   \n",
       " 1   2024-04-13 02:30:41    AutoInt  for_testing         [768, 768]   \n",
       " 2   2024-04-13 02:30:42    AutoInt  for_testing         [768, 768]   \n",
       " 3   2024-04-13 02:30:42    AutoInt  for_testing         [768, 768]   \n",
       " 4   2024-04-13 02:30:42    AutoInt  for_testing         [768, 768]   \n",
       " ..                  ...        ...          ...                ...   \n",
       " 95  2024-04-13 02:31:18    AutoInt  for_testing         [768, 768]   \n",
       " 96  2024-04-13 02:31:19    AutoInt  for_testing         [768, 768]   \n",
       " 97  2024-04-13 02:31:19    AutoInt  for_testing         [768, 768]   \n",
       " 98  2024-04-13 02:31:20    AutoInt  for_testing         [768, 768]   \n",
       " 99  2024-04-13 02:31:20    AutoInt  for_testing         [768, 768]   \n",
       " \n",
       "     AutoInt_embed_dim  AutoInt_atten_embed_dim  AutoInt_num_heads  \\\n",
       " 0                 768                       32                  2   \n",
       " 1                 768                       32                  2   \n",
       " 2                 768                       32                  2   \n",
       " 3                 768                       32                  2   \n",
       " 4                 768                       32                  2   \n",
       " ..                ...                      ...                ...   \n",
       " 95                768                       32                  2   \n",
       " 96                768                       32                  2   \n",
       " 97                768                       32                  2   \n",
       " 98                768                       32                  2   \n",
       " 99                768                       32                  2   \n",
       " \n",
       "     AutoInt_num_layers AutoInt_mlp_dims AutoInt_dropouts  ...  \\\n",
       " 0                    3  (256, 256, 256)  (0.5, 0.5, 0.5)  ...   \n",
       " 1                    3  (256, 256, 256)  (0.5, 0.5, 0.5)  ...   \n",
       " 2                    3  (256, 256, 256)  (0.5, 0.5, 0.5)  ...   \n",
       " 3                    3  (256, 256, 256)  (0.5, 0.5, 0.5)  ...   \n",
       " 4                    3  (256, 256, 256)  (0.5, 0.5, 0.5)  ...   \n",
       " ..                 ...              ...              ...  ...   \n",
       " 95                   3  (256, 256, 256)  (0.5, 0.5, 0.5)  ...   \n",
       " 96                   3  (256, 256, 256)  (0.5, 0.5, 0.5)  ...   \n",
       " 97                   3  (256, 256, 256)  (0.5, 0.5, 0.5)  ...   \n",
       " 98                   3  (256, 256, 256)  (0.5, 0.5, 0.5)  ...   \n",
       " 99                   3  (256, 256, 256)  (0.5, 0.5, 0.5)  ...   \n",
       " \n",
       "     Epoch/Epochs_num  Avg_Loss  Avg_RMSE   Avg_MSE  Avg_Accuracy  \\\n",
       " 0            1th/100  3.370611  1.684048  3.370611           0.0   \n",
       " 1            2th/100  0.973443  0.985305  0.973443           0.0   \n",
       " 2            3th/100  0.885287  0.940335  0.885287           0.0   \n",
       " 3            4th/100  0.880859  0.937150  0.880859           0.0   \n",
       " 4            5th/100  0.838960  0.915550  0.838960           0.0   \n",
       " ..               ...       ...       ...       ...           ...   \n",
       " 95          96th/100  0.126570  0.352853  0.126570           0.0   \n",
       " 96          97th/100  0.099581  0.314857  0.099581           0.0   \n",
       " 97          98th/100  0.082964  0.287104  0.082964           0.0   \n",
       " 98          99th/100  0.075893  0.274753  0.075893           0.0   \n",
       " 99         100th/100  0.081360  0.284432  0.081360           0.0   \n",
       " \n",
       "     Avg_AUC_score  Avg_F1 Avg_Precision  Avg_Recall  Avg_Specificity  \n",
       " 0             0.0     0.0           0.0         0.0              0.0  \n",
       " 1             0.0     0.0           0.0         0.0              0.0  \n",
       " 2             0.0     0.0           0.0         0.0              0.0  \n",
       " 3             0.0     0.0           0.0         0.0              0.0  \n",
       " 4             0.0     0.0           0.0         0.0              0.0  \n",
       " ..            ...     ...           ...         ...              ...  \n",
       " 95            0.0     0.0           0.0         0.0              0.0  \n",
       " 96            0.0     0.0           0.0         0.0              0.0  \n",
       " 97            0.0     0.0           0.0         0.0              0.0  \n",
       " 98            0.0     0.0           0.0         0.0              0.0  \n",
       " 99            0.0     0.0           0.0         0.0              0.0  \n",
       " \n",
       " [100 rows x 27 columns],\n",
       "               Timestamp Model_name AutoInt_field_dims  AutoInt_embed_dim  \\\n",
       " 0   2024-04-13 02:30:41    AutoInt         [768, 768]                768   \n",
       " 1   2024-04-13 02:30:41    AutoInt         [768, 768]                768   \n",
       " 2   2024-04-13 02:30:42    AutoInt         [768, 768]                768   \n",
       " 3   2024-04-13 02:30:42    AutoInt         [768, 768]                768   \n",
       " 4   2024-04-13 02:30:42    AutoInt         [768, 768]                768   \n",
       " ..                  ...        ...                ...                ...   \n",
       " 95  2024-04-13 02:31:18    AutoInt         [768, 768]                768   \n",
       " 96  2024-04-13 02:31:19    AutoInt         [768, 768]                768   \n",
       " 97  2024-04-13 02:31:19    AutoInt         [768, 768]                768   \n",
       " 98  2024-04-13 02:31:20    AutoInt         [768, 768]                768   \n",
       " 99  2024-04-13 02:31:20    AutoInt         [768, 768]                768   \n",
       " \n",
       "     AutoInt_atten_embed_dim  AutoInt_num_heads  AutoInt_num_layers  \\\n",
       " 0                        32                  2                   3   \n",
       " 1                        32                  2                   3   \n",
       " 2                        32                  2                   3   \n",
       " 3                        32                  2                   3   \n",
       " 4                        32                  2                   3   \n",
       " ..                      ...                ...                 ...   \n",
       " 95                       32                  2                   3   \n",
       " 96                       32                  2                   3   \n",
       " 97                       32                  2                   3   \n",
       " 98                       32                  2                   3   \n",
       " 99                       32                  2                   3   \n",
       " \n",
       "    AutoInt_mlp_dims AutoInt_dropouts  AutoInt_has_residual  ...  \\\n",
       " 0   (256, 256, 256)  (0.5, 0.5, 0.5)                  True  ...   \n",
       " 1   (256, 256, 256)  (0.5, 0.5, 0.5)                  True  ...   \n",
       " 2   (256, 256, 256)  (0.5, 0.5, 0.5)                  True  ...   \n",
       " 3   (256, 256, 256)  (0.5, 0.5, 0.5)                  True  ...   \n",
       " 4   (256, 256, 256)  (0.5, 0.5, 0.5)                  True  ...   \n",
       " ..              ...              ...                   ...  ...   \n",
       " 95  (256, 256, 256)  (0.5, 0.5, 0.5)                  True  ...   \n",
       " 96  (256, 256, 256)  (0.5, 0.5, 0.5)                  True  ...   \n",
       " 97  (256, 256, 256)  (0.5, 0.5, 0.5)                  True  ...   \n",
       " 98  (256, 256, 256)  (0.5, 0.5, 0.5)                  True  ...   \n",
       " 99  (256, 256, 256)  (0.5, 0.5, 0.5)                  True  ...   \n",
       " \n",
       "    Epoch/Epochs_num            Loss      RMSE       MSE  Accuracy  AUC_score  \\\n",
       " 0           1th/100  tensor(1.2173)  1.103297  1.217265       0.0        0.0   \n",
       " 1           2th/100  tensor(0.9195)  0.958902  0.919493       0.0        0.0   \n",
       " 2           3th/100  tensor(0.8709)  0.933225  0.870908       0.0        0.0   \n",
       " 3           4th/100  tensor(0.8717)  0.933655  0.871712       0.0        0.0   \n",
       " 4           5th/100  tensor(0.8661)  0.930623  0.866059       0.0        0.0   \n",
       " ..              ...             ...       ...       ...       ...        ...   \n",
       " 95         96th/100  tensor(1.2878)  1.134829  1.287836       0.0        0.0   \n",
       " 96         97th/100  tensor(1.2954)  1.138140  1.295364       0.0        0.0   \n",
       " 97         98th/100  tensor(1.2841)  1.133200  1.284142       0.0        0.0   \n",
       " 98         99th/100  tensor(1.3118)  1.145357  1.311844       0.0        0.0   \n",
       " 99        100th/100  tensor(1.3175)  1.147819  1.317489       0.0        0.0   \n",
       " \n",
       "      F1 Precision  Recall  Specificity  \n",
       " 0   0.0       0.0     0.0          0.0  \n",
       " 1   0.0       0.0     0.0          0.0  \n",
       " 2   0.0       0.0     0.0          0.0  \n",
       " 3   0.0       0.0     0.0          0.0  \n",
       " 4   0.0       0.0     0.0          0.0  \n",
       " ..  ...       ...     ...          ...  \n",
       " 95  0.0       0.0     0.0          0.0  \n",
       " 96  0.0       0.0     0.0          0.0  \n",
       " 97  0.0       0.0     0.0          0.0  \n",
       " 98  0.0       0.0     0.0          0.0  \n",
       " 99  0.0       0.0     0.0          0.0  \n",
       " \n",
       " [100 rows x 26 columns])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training and testing\n",
    "\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8080\")\n",
    "mlflow.set_experiment(\"ori_f4_bbs_tt/AutoInt\")\n",
    "\n",
    "mlflow_model_training_validtion_or_testing(X_train, y_train, X_test, y_test, \n",
    "                             \"AutoInt\", **test_AutoInt_params, save_records=True, testing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96a0b59",
   "metadata": {},
   "source": [
    "# MLP experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef2985a",
   "metadata": {},
   "source": [
    "Training, Validating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02d571bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP\n",
    "# input_dim, embed_dims, dropout\n",
    "\n",
    "input_dim = len(X_train[0])\n",
    "embedding_size = 768\n",
    "field_num = len(columns_to_train)\n",
    "\n",
    "MLP_params = {\n",
    "    'hyperparameters': {\n",
    "        'input_dim': input_dim, \n",
    "#         'factors_num': [5, 10, 15],\n",
    "        'embed_dims': (256, 256, 256),\n",
    "        'dropout': 0.0\n",
    "    },\n",
    "\n",
    "    'task_type': 'Regression', 'loss_type': 'MSE', 'optimizer_type': 'Adam', \n",
    "#         'dl_learning_rate': [0.01, 0.02, 0.001], \n",
    "    'dl_learning_rate': 0.001,\n",
    "    'epochs_num': 100, \n",
    "#         'batch_size': [100, 500, 1000]\n",
    "    'batch_size': 512\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "841aa432",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/04/13 02:31:22 INFO mlflow.tracking.fluent: Experiment with name 'ori_f4_bbs_tv/MLP' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training MLP model ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n",
      "Start validating ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/mlflow/types/utils.py:393: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(              Timestamp Model_name    Training_for  MLP_input_dim  \\\n",
       " 0   2024-04-13 02:31:23        MLP  for_validation           1536   \n",
       " 1   2024-04-13 02:31:23        MLP  for_validation           1536   \n",
       " 2   2024-04-13 02:31:23        MLP  for_validation           1536   \n",
       " 3   2024-04-13 02:31:23        MLP  for_validation           1536   \n",
       " 4   2024-04-13 02:31:24        MLP  for_validation           1536   \n",
       " ..                  ...        ...             ...            ...   \n",
       " 95  2024-04-13 02:31:47        MLP  for_validation           1536   \n",
       " 96  2024-04-13 02:31:48        MLP  for_validation           1536   \n",
       " 97  2024-04-13 02:31:48        MLP  for_validation           1536   \n",
       " 98  2024-04-13 02:31:48        MLP  for_validation           1536   \n",
       " 99  2024-04-13 02:31:49        MLP  for_validation           1536   \n",
       " \n",
       "      MLP_embed_dims  MLP_dropout   Task_type Loss_type Optimizer_type  \\\n",
       " 0   (256, 256, 256)          0.0  Regression       MSE           Adam   \n",
       " 1   (256, 256, 256)          0.0  Regression       MSE           Adam   \n",
       " 2   (256, 256, 256)          0.0  Regression       MSE           Adam   \n",
       " 3   (256, 256, 256)          0.0  Regression       MSE           Adam   \n",
       " 4   (256, 256, 256)          0.0  Regression       MSE           Adam   \n",
       " ..              ...          ...         ...       ...            ...   \n",
       " 95  (256, 256, 256)          0.0  Regression       MSE           Adam   \n",
       " 96  (256, 256, 256)          0.0  Regression       MSE           Adam   \n",
       " 97  (256, 256, 256)          0.0  Regression       MSE           Adam   \n",
       " 98  (256, 256, 256)          0.0  Regression       MSE           Adam   \n",
       " 99  (256, 256, 256)          0.0  Regression       MSE           Adam   \n",
       " \n",
       "     DL_learning_rate  ...  Epoch/Epochs_num   Avg_Loss  Avg_RMSE    Avg_MSE  \\\n",
       " 0              0.001  ...           1th/100  10.057400  3.100183  10.057400   \n",
       " 1              0.001  ...           2th/100   2.059814  1.302555   2.059814   \n",
       " 2              0.001  ...           3th/100   0.936014  0.966536   0.936014   \n",
       " 3              0.001  ...           4th/100   0.902358  0.949319   0.902358   \n",
       " 4              0.001  ...           5th/100   0.856750  0.925133   0.856750   \n",
       " ..               ...  ...               ...        ...       ...        ...   \n",
       " 95             0.001  ...          96th/100   0.134938  0.366680   0.134938   \n",
       " 96             0.001  ...          97th/100   0.135485  0.367006   0.135485   \n",
       " 97             0.001  ...          98th/100   0.143441  0.376342   0.143441   \n",
       " 98             0.001  ...          99th/100   0.135742  0.368009   0.135742   \n",
       " 99             0.001  ...         100th/100   0.124403  0.351953   0.124403   \n",
       " \n",
       "     Avg_Accuracy  Avg_AUC_score  Avg_F1  Avg_Precision  Avg_Recall  \\\n",
       " 0            0.0            0.0     0.0            0.0         0.0   \n",
       " 1            0.0            0.0     0.0            0.0         0.0   \n",
       " 2            0.0            0.0     0.0            0.0         0.0   \n",
       " 3            0.0            0.0     0.0            0.0         0.0   \n",
       " 4            0.0            0.0     0.0            0.0         0.0   \n",
       " ..           ...            ...     ...            ...         ...   \n",
       " 95           0.0            0.0     0.0            0.0         0.0   \n",
       " 96           0.0            0.0     0.0            0.0         0.0   \n",
       " 97           0.0            0.0     0.0            0.0         0.0   \n",
       " 98           0.0            0.0     0.0            0.0         0.0   \n",
       " 99           0.0            0.0     0.0            0.0         0.0   \n",
       " \n",
       "     Avg_Specificity  \n",
       " 0               0.0  \n",
       " 1               0.0  \n",
       " 2               0.0  \n",
       " 3               0.0  \n",
       " 4               0.0  \n",
       " ..              ...  \n",
       " 95              0.0  \n",
       " 96              0.0  \n",
       " 97              0.0  \n",
       " 98              0.0  \n",
       " 99              0.0  \n",
       " \n",
       " [100 rows x 22 columns],\n",
       "               Timestamp Model_name  MLP_input_dim   MLP_embed_dims  \\\n",
       " 0   2024-04-13 02:31:23        MLP           1536  (256, 256, 256)   \n",
       " 1   2024-04-13 02:31:23        MLP           1536  (256, 256, 256)   \n",
       " 2   2024-04-13 02:31:23        MLP           1536  (256, 256, 256)   \n",
       " 3   2024-04-13 02:31:23        MLP           1536  (256, 256, 256)   \n",
       " 4   2024-04-13 02:31:24        MLP           1536  (256, 256, 256)   \n",
       " ..                  ...        ...            ...              ...   \n",
       " 95  2024-04-13 02:31:47        MLP           1536  (256, 256, 256)   \n",
       " 96  2024-04-13 02:31:48        MLP           1536  (256, 256, 256)   \n",
       " 97  2024-04-13 02:31:48        MLP           1536  (256, 256, 256)   \n",
       " 98  2024-04-13 02:31:48        MLP           1536  (256, 256, 256)   \n",
       " 99  2024-04-13 02:31:49        MLP           1536  (256, 256, 256)   \n",
       " \n",
       "     MLP_dropout   Task_type Loss_type Optimizer_type  DL_learning_rate  \\\n",
       " 0           0.0  Regression       MSE           Adam             0.001   \n",
       " 1           0.0  Regression       MSE           Adam             0.001   \n",
       " 2           0.0  Regression       MSE           Adam             0.001   \n",
       " 3           0.0  Regression       MSE           Adam             0.001   \n",
       " 4           0.0  Regression       MSE           Adam             0.001   \n",
       " ..          ...         ...       ...            ...               ...   \n",
       " 95          0.0  Regression       MSE           Adam             0.001   \n",
       " 96          0.0  Regression       MSE           Adam             0.001   \n",
       " 97          0.0  Regression       MSE           Adam             0.001   \n",
       " 98          0.0  Regression       MSE           Adam             0.001   \n",
       " 99          0.0  Regression       MSE           Adam             0.001   \n",
       " \n",
       "     Epochs_num  ...  Epoch/Epochs_num            Loss      RMSE       MSE  \\\n",
       " 0          100  ...           1th/100  tensor(8.6229)  2.936486  8.622947   \n",
       " 1          100  ...           2th/100  tensor(1.0091)  1.004549  1.009119   \n",
       " 2          100  ...           3th/100  tensor(0.9855)  0.992743  0.985538   \n",
       " 3          100  ...           4th/100  tensor(0.9396)  0.969329  0.939598   \n",
       " 4          100  ...           5th/100  tensor(0.9291)  0.963904  0.929112   \n",
       " ..         ...  ...               ...             ...       ...       ...   \n",
       " 95         100  ...          96th/100  tensor(1.3040)  1.141914  1.303967   \n",
       " 96         100  ...          97th/100  tensor(1.3064)  1.142992  1.306431   \n",
       " 97         100  ...          98th/100  tensor(1.2696)  1.126763  1.269596   \n",
       " 98         100  ...          99th/100  tensor(1.3547)  1.163913  1.354693   \n",
       " 99         100  ...         100th/100  tensor(1.3152)  1.146832  1.315224   \n",
       " \n",
       "     Accuracy  AUC_score   F1  Precision  Recall  Specificity  \n",
       " 0        0.0        0.0  0.0        0.0     0.0          0.0  \n",
       " 1        0.0        0.0  0.0        0.0     0.0          0.0  \n",
       " 2        0.0        0.0  0.0        0.0     0.0          0.0  \n",
       " 3        0.0        0.0  0.0        0.0     0.0          0.0  \n",
       " 4        0.0        0.0  0.0        0.0     0.0          0.0  \n",
       " ..       ...        ...  ...        ...     ...          ...  \n",
       " 95       0.0        0.0  0.0        0.0     0.0          0.0  \n",
       " 96       0.0        0.0  0.0        0.0     0.0          0.0  \n",
       " 97       0.0        0.0  0.0        0.0     0.0          0.0  \n",
       " 98       0.0        0.0  0.0        0.0     0.0          0.0  \n",
       " 99       0.0        0.0  0.0        0.0     0.0          0.0  \n",
       " \n",
       " [100 rows x 21 columns])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training and validating\n",
    "\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8080\")\n",
    "mlflow.set_experiment(\"ori_f4_bbs_tv/MLP\")\n",
    "\n",
    "mlflow_model_training_validtion_or_testing(X_train, y_train, X_valid, y_valid, \n",
    "                             \"MLP\", **MLP_params, save_records=True, testing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d138a3f8",
   "metadata": {},
   "source": [
    "Training, Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04b8ae8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP\n",
    "# input_dim, embed_dims, dropout\n",
    "\n",
    "input_dim = len(X_train[0])\n",
    "embedding_size = 768\n",
    "field_num = len(columns_to_train)\n",
    "\n",
    "test_MLP_params = {\n",
    "    'hyperparameters': {\n",
    "        'input_dim': input_dim,\n",
    "        'embed_dims': (256, 256, 256),\n",
    "        'dropout': 0.0\n",
    "    },\n",
    "\n",
    "    'task_type': 'Regression', 'loss_type': 'MSE', 'optimizer_type': 'Adam', \n",
    "    'dl_learning_rate': 0.001,\n",
    "    'epochs_num': 100, \n",
    "    'batch_size': 512\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6be6a000",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/04/13 02:31:51 INFO mlflow.tracking.fluent: Experiment with name 'ori_f4_bbs_tt/MLP' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training MLP model ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n",
      "Start testing ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/mlflow/types/utils.py:393: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(              Timestamp Model_name Training_for  MLP_input_dim  \\\n",
       " 0   2024-04-13 02:31:51        MLP  for_testing           1536   \n",
       " 1   2024-04-13 02:31:51        MLP  for_testing           1536   \n",
       " 2   2024-04-13 02:31:51        MLP  for_testing           1536   \n",
       " 3   2024-04-13 02:31:52        MLP  for_testing           1536   \n",
       " 4   2024-04-13 02:31:52        MLP  for_testing           1536   \n",
       " ..                  ...        ...          ...            ...   \n",
       " 95  2024-04-13 02:32:17        MLP  for_testing           1536   \n",
       " 96  2024-04-13 02:32:17        MLP  for_testing           1536   \n",
       " 97  2024-04-13 02:32:17        MLP  for_testing           1536   \n",
       " 98  2024-04-13 02:32:17        MLP  for_testing           1536   \n",
       " 99  2024-04-13 02:32:18        MLP  for_testing           1536   \n",
       " \n",
       "      MLP_embed_dims  MLP_dropout   Task_type Loss_type Optimizer_type  \\\n",
       " 0   (256, 256, 256)          0.0  Regression       MSE           Adam   \n",
       " 1   (256, 256, 256)          0.0  Regression       MSE           Adam   \n",
       " 2   (256, 256, 256)          0.0  Regression       MSE           Adam   \n",
       " 3   (256, 256, 256)          0.0  Regression       MSE           Adam   \n",
       " 4   (256, 256, 256)          0.0  Regression       MSE           Adam   \n",
       " ..              ...          ...         ...       ...            ...   \n",
       " 95  (256, 256, 256)          0.0  Regression       MSE           Adam   \n",
       " 96  (256, 256, 256)          0.0  Regression       MSE           Adam   \n",
       " 97  (256, 256, 256)          0.0  Regression       MSE           Adam   \n",
       " 98  (256, 256, 256)          0.0  Regression       MSE           Adam   \n",
       " 99  (256, 256, 256)          0.0  Regression       MSE           Adam   \n",
       " \n",
       "     DL_learning_rate  ...  Epoch/Epochs_num  Avg_Loss  Avg_RMSE   Avg_MSE  \\\n",
       " 0              0.001  ...           1th/100  9.528281  3.012832  9.528281   \n",
       " 1              0.001  ...           2th/100  1.789277  1.227176  1.789277   \n",
       " 2              0.001  ...           3th/100  0.920912  0.959048  0.920912   \n",
       " 3              0.001  ...           4th/100  0.884931  0.939886  0.884931   \n",
       " 4              0.001  ...           5th/100  0.854410  0.923812  0.854410   \n",
       " ..               ...  ...               ...       ...       ...       ...   \n",
       " 95             0.001  ...          96th/100  0.125977  0.352755  0.125977   \n",
       " 96             0.001  ...          97th/100  0.117254  0.342113  0.117254   \n",
       " 97             0.001  ...          98th/100  0.107502  0.327499  0.107502   \n",
       " 98             0.001  ...          99th/100  0.098196  0.313078  0.098196   \n",
       " 99             0.001  ...         100th/100  0.092131  0.302891  0.092131   \n",
       " \n",
       "     Avg_Accuracy  Avg_AUC_score  Avg_F1  Avg_Precision  Avg_Recall  \\\n",
       " 0            0.0            0.0     0.0            0.0         0.0   \n",
       " 1            0.0            0.0     0.0            0.0         0.0   \n",
       " 2            0.0            0.0     0.0            0.0         0.0   \n",
       " 3            0.0            0.0     0.0            0.0         0.0   \n",
       " 4            0.0            0.0     0.0            0.0         0.0   \n",
       " ..           ...            ...     ...            ...         ...   \n",
       " 95           0.0            0.0     0.0            0.0         0.0   \n",
       " 96           0.0            0.0     0.0            0.0         0.0   \n",
       " 97           0.0            0.0     0.0            0.0         0.0   \n",
       " 98           0.0            0.0     0.0            0.0         0.0   \n",
       " 99           0.0            0.0     0.0            0.0         0.0   \n",
       " \n",
       "     Avg_Specificity  \n",
       " 0               0.0  \n",
       " 1               0.0  \n",
       " 2               0.0  \n",
       " 3               0.0  \n",
       " 4               0.0  \n",
       " ..              ...  \n",
       " 95              0.0  \n",
       " 96              0.0  \n",
       " 97              0.0  \n",
       " 98              0.0  \n",
       " 99              0.0  \n",
       " \n",
       " [100 rows x 22 columns],\n",
       "               Timestamp Model_name  MLP_input_dim   MLP_embed_dims  \\\n",
       " 0   2024-04-13 02:31:51        MLP           1536  (256, 256, 256)   \n",
       " 1   2024-04-13 02:31:51        MLP           1536  (256, 256, 256)   \n",
       " 2   2024-04-13 02:31:51        MLP           1536  (256, 256, 256)   \n",
       " 3   2024-04-13 02:31:52        MLP           1536  (256, 256, 256)   \n",
       " 4   2024-04-13 02:31:52        MLP           1536  (256, 256, 256)   \n",
       " ..                  ...        ...            ...              ...   \n",
       " 95  2024-04-13 02:32:17        MLP           1536  (256, 256, 256)   \n",
       " 96  2024-04-13 02:32:17        MLP           1536  (256, 256, 256)   \n",
       " 97  2024-04-13 02:32:17        MLP           1536  (256, 256, 256)   \n",
       " 98  2024-04-13 02:32:18        MLP           1536  (256, 256, 256)   \n",
       " 99  2024-04-13 02:32:18        MLP           1536  (256, 256, 256)   \n",
       " \n",
       "     MLP_dropout   Task_type Loss_type Optimizer_type  DL_learning_rate  \\\n",
       " 0           0.0  Regression       MSE           Adam             0.001   \n",
       " 1           0.0  Regression       MSE           Adam             0.001   \n",
       " 2           0.0  Regression       MSE           Adam             0.001   \n",
       " 3           0.0  Regression       MSE           Adam             0.001   \n",
       " 4           0.0  Regression       MSE           Adam             0.001   \n",
       " ..          ...         ...       ...            ...               ...   \n",
       " 95          0.0  Regression       MSE           Adam             0.001   \n",
       " 96          0.0  Regression       MSE           Adam             0.001   \n",
       " 97          0.0  Regression       MSE           Adam             0.001   \n",
       " 98          0.0  Regression       MSE           Adam             0.001   \n",
       " 99          0.0  Regression       MSE           Adam             0.001   \n",
       " \n",
       "     Epochs_num  ...  Epoch/Epochs_num            Loss      RMSE       MSE  \\\n",
       " 0          100  ...           1th/100  tensor(8.9561)  2.992672  8.956084   \n",
       " 1          100  ...           2th/100  tensor(0.9367)  0.967815  0.936666   \n",
       " 2          100  ...           3th/100  tensor(0.9656)  0.982633  0.965567   \n",
       " 3          100  ...           4th/100  tensor(0.8808)  0.938509  0.880798   \n",
       " 4          100  ...           5th/100  tensor(0.8859)  0.941207  0.885871   \n",
       " ..         ...  ...               ...             ...       ...       ...   \n",
       " 95         100  ...          96th/100  tensor(1.2485)  1.117367  1.248510   \n",
       " 96         100  ...          97th/100  tensor(1.1886)  1.090235  1.188613   \n",
       " 97         100  ...          98th/100  tensor(1.2098)  1.099895  1.209769   \n",
       " 98         100  ...          99th/100  tensor(1.2039)  1.097246  1.203948   \n",
       " 99         100  ...         100th/100  tensor(1.2304)  1.109235  1.230402   \n",
       " \n",
       "     Accuracy  AUC_score   F1  Precision  Recall  Specificity  \n",
       " 0        0.0        0.0  0.0        0.0     0.0          0.0  \n",
       " 1        0.0        0.0  0.0        0.0     0.0          0.0  \n",
       " 2        0.0        0.0  0.0        0.0     0.0          0.0  \n",
       " 3        0.0        0.0  0.0        0.0     0.0          0.0  \n",
       " 4        0.0        0.0  0.0        0.0     0.0          0.0  \n",
       " ..       ...        ...  ...        ...     ...          ...  \n",
       " 95       0.0        0.0  0.0        0.0     0.0          0.0  \n",
       " 96       0.0        0.0  0.0        0.0     0.0          0.0  \n",
       " 97       0.0        0.0  0.0        0.0     0.0          0.0  \n",
       " 98       0.0        0.0  0.0        0.0     0.0          0.0  \n",
       " 99       0.0        0.0  0.0        0.0     0.0          0.0  \n",
       " \n",
       " [100 rows x 21 columns])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training and testing\n",
    "\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8080\")\n",
    "mlflow.set_experiment(\"ori_f4_bbs_tt/MLP\")\n",
    "\n",
    "mlflow_model_training_validtion_or_testing(X_train, y_train, X_test, y_test, \n",
    "                             \"MLP\", **test_MLP_params, save_records=True, testing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182d592e",
   "metadata": {},
   "source": [
    "# XGBoost experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c95eb6",
   "metadata": {},
   "source": [
    "Training, Validating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ecd5437",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBoost_params = {\n",
    "    'hyperparameters': {\n",
    "#         'learning_rate': [0.01, 0.02, 0.001],\n",
    "#         'learning_rate': [i/100 for i in range(1, 11)],\n",
    "        'learning_rate': 0.001,\n",
    "#         'n_estimators': [50, 100],\n",
    "#         'n_estimators': [20, 40, 60, 80, 100],\n",
    "        'n_estimators': 50,\n",
    "#         'subsample': [1],\n",
    "#         'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "        'subsample': 1,\n",
    "#         'colsample_bytree': [1]\n",
    "#         'colsample_bytree': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "        'colsample_bytree': 1\n",
    "    },\n",
    "    'task_type': 'Regression', 'loss_type': None, 'optimizer_type': None, \n",
    "    'dl_learning_rate': None, 'epochs_num': None, 'batch_size': None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4317b287",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/04/13 02:32:20 INFO mlflow.tracking.fluent: Experiment with name 'ori_f4_bbs_tv/XGBoost' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training XGBoost model ...\n",
      "Start validating ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [02:32:23] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1240: Saving into deprecated binary model format, please consider using `json` or `ubj`. Model format will default to JSON in XGBoost 2.2 if not specified.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(             Timestamp Model_name    Training_for  XGBoost_learning_rate  \\\n",
       " 0  2024-04-13 02:32:23    XGBoost  for_validation                  0.001   \n",
       " \n",
       "    XGBoost_n_estimators  XGBoost_subsample  XGBoost_colsample_bytree  \\\n",
       " 0                    50                  1                         1   \n",
       " \n",
       "     Task_type      RMSE       MSE  Accuracy  AUC_score   F1  Precision  \\\n",
       " 0  Regression  0.967263  0.935598       0.0        0.0  0.0        0.0   \n",
       " \n",
       "    Recall  Specificity  \n",
       " 0     0.0          0.0  ,\n",
       "              Timestamp Model_name  XGBoost_learning_rate  \\\n",
       " 0  2024-04-13 02:32:23    XGBoost                  0.001   \n",
       " \n",
       "    XGBoost_n_estimators  XGBoost_subsample  XGBoost_colsample_bytree  \\\n",
       " 0                    50                  1                         1   \n",
       " \n",
       "     Task_type      RMSE       MSE  Accuracy  AUC_score   F1  Precision  \\\n",
       " 0  Regression  0.972876  0.946487       0.0        0.0  0.0        0.0   \n",
       " \n",
       "    Recall  Specificity  \n",
       " 0     0.0          0.0  )"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training and validating\n",
    "\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8080\")\n",
    "mlflow.set_experiment(\"ori_f4_bbs_tv/XGBoost\")\n",
    "\n",
    "mlflow_model_training_validtion_or_testing(X_train, y_train, X_valid, y_valid, \n",
    "                             \"XGBoost\", **XGBoost_params, save_records=True, testing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c29ee1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Specify the directory containing the MLmodel file\n",
    "# model_dir = \"runs:/3977b38e236146fb8129aed388b68875/XGBoost_model\"\n",
    "\n",
    "# # Load the PyTorch model from the specified directory\n",
    "# model = mlflow.xgboost.load_model(model_dir)\n",
    "\n",
    "# booster = model.get_booster()\n",
    "\n",
    "# feature_importance = booster.get_score(importance_type='weight')\n",
    "\n",
    "# print(feature_importance) # lengh of feature importance != num of features ??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc918388",
   "metadata": {},
   "source": [
    "Training, Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d071b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_XGBoost_params = {\n",
    "    'hyperparameters': {\n",
    "        'learning_rate': 0.001,\n",
    "        'n_estimators': 50,\n",
    "        'subsample': 1,\n",
    "        'colsample_bytree': 1\n",
    "    },\n",
    "    'task_type': 'Regression', 'loss_type': None, 'optimizer_type': None, \n",
    "    'dl_learning_rate': None, 'epochs_num': None, 'batch_size': None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "415878b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/04/13 02:32:25 INFO mlflow.tracking.fluent: Experiment with name 'ori_f4_bbs_tt/XGBoost' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training XGBoost model ...\n",
      "Start testing ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [02:32:28] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1240: Saving into deprecated binary model format, please consider using `json` or `ubj`. Model format will default to JSON in XGBoost 2.2 if not specified.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(             Timestamp Model_name Training_for  XGBoost_learning_rate  \\\n",
       " 0  2024-04-13 02:32:28    XGBoost  for_testing                  0.001   \n",
       " \n",
       "    XGBoost_n_estimators  XGBoost_subsample  XGBoost_colsample_bytree  \\\n",
       " 0                    50                  1                         1   \n",
       " \n",
       "     Task_type      RMSE       MSE  Accuracy  AUC_score   F1  Precision  \\\n",
       " 0  Regression  0.967263  0.935598       0.0        0.0  0.0        0.0   \n",
       " \n",
       "    Recall  Specificity  \n",
       " 0     0.0          0.0  ,\n",
       "              Timestamp Model_name  XGBoost_learning_rate  \\\n",
       " 0  2024-04-13 02:32:28    XGBoost                  0.001   \n",
       " \n",
       "    XGBoost_n_estimators  XGBoost_subsample  XGBoost_colsample_bytree  \\\n",
       " 0                    50                  1                         1   \n",
       " \n",
       "     Task_type     RMSE       MSE  Accuracy  AUC_score   F1  Precision  Recall  \\\n",
       " 0  Regression  0.95637  0.914644       0.0        0.0  0.0        0.0     0.0   \n",
       " \n",
       "    Specificity  \n",
       " 0          0.0  )"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training and testing\n",
    "\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8080\")\n",
    "mlflow.set_experiment(\"ori_f4_bbs_tt/XGBoost\")\n",
    "\n",
    "mlflow_model_training_validtion_or_testing(X_train, y_train, X_test, y_test, \n",
    "                             \"XGBoost\", **test_XGBoost_params, save_records=True, testing=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
